{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gorillatracker.model.wrappers_ssl import MoCoWrapper\n",
    "from gorillatracker.utils.embedding_generator import generate_embeddings, df_from_predictions\n",
    "from pathlib import Path\n",
    "from gorillatracker.data.nlet_dm import NletDataModule\n",
    "from gorillatracker.data.nlet import build_onelet, SupervisedDataset, SupervisedKFoldDataset\n",
    "from torchvision.transforms import Resize, Normalize, Compose\n",
    "import pandas as pd\n",
    "\n",
    "# TODO(liamvdv): @robert: why filtered? Worauf sind die Dataset Stats?\n",
    "BRISTOL = Path(\n",
    "    \"/workspaces/gorillatracker/data/supervised/bristol/cross_encounter_validation/cropped_frames_square_filtered\"\n",
    ")\n",
    "SPAC = Path(\"/workspaces/gorillatracker/data/supervised/cxl_all/face_images_square\")\n",
    "\n",
    "\n",
    "def get_moco_model(\n",
    "    checkpoint_path: str = \"/workspaces/gorillatracker/models/ssl/moco-accuracy-0.58.ckpt\",\n",
    ") -> MoCoWrapper:\n",
    "    return MoCoWrapper.load_from_checkpoint(checkpoint_path=checkpoint_path, data_module=None, wandb_run=None)\n",
    "\n",
    "def get_moco_pretrained_model(\n",
    ") -> MoCoWrapper:\n",
    "    # TODO(liamvdv): add pretrained vit dino_v2 model\n",
    "    return get_moco_model(\"/workspaces/gorillatracker/models/ssl/vit-dino-v2????.ckpt\")\n",
    "\n",
    "def get_model_transforms(model):\n",
    "    resize = getattr(model, \"data_resize_transform\", (224, 224))\n",
    "    model_transforms = Resize(resize)\n",
    "    normalize_transform = Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    use_normalization = getattr(model, \"use_normalization\", True)\n",
    "    # NOTE(liamvdv): normalization_mean, normalization_std are always default.\n",
    "    if use_normalization:\n",
    "        model_transforms = Compose([model_transforms, normalize_transform])\n",
    "    return model_transforms\n",
    "\n",
    "\n",
    "def _get_dataloader(model, path: Path):\n",
    "    data_module = NletDataModule(\n",
    "        data_dir=path,\n",
    "        dataset_class=SupervisedDataset,\n",
    "        nlet_builder=build_onelet,\n",
    "        batch_size=64,\n",
    "        workers=10,\n",
    "        model_transforms=get_model_transforms(model),\n",
    "        training_transforms=lambda x: x,\n",
    "        dataset_names=[\"Showcase\"],\n",
    "    )\n",
    "\n",
    "    data_module.setup(\"validate\")\n",
    "    dls = data_module.val_dataloader()  # val for transforms\n",
    "    assert len(dls) == 1\n",
    "    dl = dls[0]\n",
    "    return dl\n",
    "\n",
    "\n",
    "def get_df(model, path: Path):\n",
    "    dl = _get_dataloader(model, path)\n",
    "    preds = generate_embeddings(model, dl)\n",
    "    df = df_from_predictions(preds)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(liamvdv): add other models; make column on dataframe.\n",
    "# TODO(liamvdv): merge both datasets into one dataframe, keep column for dataset identifier.\n",
    "model = get_moco_model()\n",
    "bristol = get_df(model, BRISTOL)\n",
    "bristol.to_pickle(\"bristol.pkl\")\n",
    "spac = get_df(model, SPAC)\n",
    "spac.to_pickle(\"spac.pkl\")\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
