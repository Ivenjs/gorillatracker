{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gorillatracker.model.wrappers_ssl import MoCoWrapper\n",
    "from gorillatracker.utils.embedding_generator import generate_embeddings, df_from_predictions\n",
    "from gorillatracker.model.wrappers_supervised import TimmEvalWrapper, BaseModuleSupervised\n",
    "from pathlib import Path\n",
    "from gorillatracker.data.nlet_dm import NletDataModule\n",
    "from gorillatracker.data.nlet import build_onelet, SupervisedDataset\n",
    "from torchvision.transforms import Resize, Normalize, Compose\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_finetuned_vit() -> MoCoWrapper:\n",
    "    # ViT Large + DinoV2; finetuned with SSL and MoCo Loss\n",
    "    # https://wandb.ai/gorillas/Embedding-VitLarge-MoCo-Face-Sweep/runs/rlemhfix\n",
    "    finetuned = \"/workspaces/gorillatracker/models/ssl/moco-accuracy-0.58.ckpt\"\n",
    "    return MoCoWrapper.load_from_checkpoint(\n",
    "        checkpoint_path=finetuned,\n",
    "        data_module=None,\n",
    "        wandb_run=None,\n",
    "    )\n",
    "\n",
    "def get_mock_loss_kwargs() -> dict:\n",
    "    return {\n",
    "        'margin': 1.0,  # From the file\n",
    "        's': 64.0,  # From the file\n",
    "        'temperature': 0.07,  # Default value, not specified in the file\n",
    "        'memory_bank_size': 4096,  # Default value, not specified in the file\n",
    "        'embedding_size': 128,  # From the file\n",
    "        'batch_size': 64,  # From the file\n",
    "        'num_classes': None,  # Default value, not specified in the file\n",
    "        'class_distribution': None,  # Default value, not specified in the file\n",
    "        'use_focal_loss': False,  # Default value, not specified in the file\n",
    "        'k_subcenters': 1,  # Default value, not specified in the file\n",
    "        'accelerator': 'cuda',  # From the file\n",
    "        'label_smoothing': 0.1,  # Default value, not specified in the file\n",
    "        'l2_alpha': 0.1,  # From the file\n",
    "        'l2_beta': 0.01,  # From the file\n",
    "        'path_to_pretrained_weights': \"\",  # From the file\n",
    "        'use_class_weights': False,  # Default value, not specified in the file\n",
    "        'use_dist_term': False,  # Default value, not specified in the file\n",
    "    }\n",
    "\n",
    "\n",
    "def get_pretrained_vit() -> TimmEvalWrapper:\n",
    "    # ViT Large + DinoV2\n",
    "    model = BaseModuleSupervised(\n",
    "        model_name_or_path=\"timm_eval/vit_large_patch14_dinov2.lvd142m\",\n",
    "        fix_img_size=224,\n",
    "        freeze_backbone=True,\n",
    "        wandb_run=None,\n",
    "        data_module=None,\n",
    "        loss_mode=\"offline\",\n",
    "        **get_mock_loss_kwargs(),\n",
    "    )\n",
    "    # model = TimmEvalWrapper(\n",
    "    #     backbone_name=\"vit_large_patch14_dinov2.lvd142m\",\n",
    "    #     img_size=224,\n",
    "    # )\n",
    "    # model.freeze = lambda: None\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_pretrained_efnet() -> TimmEvalWrapper:\n",
    "    # EfficientNetV2 RW_M\n",
    "    model = BaseModuleSupervised(\n",
    "        model_name_or_path=\"timm_eval/efficientnetv2_rw_m\",\n",
    "        fix_img_size=224,\n",
    "        freeze_backbone=True,\n",
    "        wandb_run=None,\n",
    "        data_module=None,\n",
    "        loss_mode=\"offline\",\n",
    "        **get_mock_loss_kwargs(),\n",
    "    )\n",
    "    # model = TimmEvalWrapper(backbone_name=\"efficientnetv2_rw_m\")\n",
    "    # model.freeze = lambda: None\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_finetuned_efnet() -> TimmEvalWrapper:\n",
    "    # EfficientNetV2 RW_M; finetuned with SSL and MoCo Loss\n",
    "    # TODO(liamvdv): add SSL trained effnet model.\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_model_transforms(model):\n",
    "    resize = getattr(model, \"data_resize_transform\", (224, 224))\n",
    "    model_transforms = Resize(resize)\n",
    "    normalize_transform = Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    use_normalization = getattr(model, \"use_normalization\", True)\n",
    "    # NOTE(liamvdv): normalization_mean, normalization_std are always default.\n",
    "    if use_normalization:\n",
    "        model_transforms = Compose([model_transforms, normalize_transform])\n",
    "    return model_transforms\n",
    "\n",
    "\n",
    "def _get_dataloader(model, path: Path):\n",
    "    data_module = NletDataModule(\n",
    "        data_dir=path,\n",
    "        dataset_class=SupervisedDataset,\n",
    "        nlet_builder=build_onelet,\n",
    "        batch_size=64,\n",
    "        workers=10,\n",
    "        model_transforms=get_model_transforms(model),\n",
    "        training_transforms=lambda x: x,\n",
    "        dataset_names=[\"Showcase\"],\n",
    "    )\n",
    "\n",
    "    data_module.setup(\"validate\")\n",
    "    dls = data_module.val_dataloader()  # val for transforms\n",
    "    assert len(dls) == 1\n",
    "    dl = dls[0]\n",
    "    return dl\n",
    "\n",
    "\n",
    "def get_df(model, path: Path):\n",
    "    dl = _get_dataloader(model, path)\n",
    "    preds = generate_embeddings(model, dl)\n",
    "    df = df_from_predictions(preds)\n",
    "    # TODO(liamvdv): Should be DF of\n",
    "    #                id, embedding, label, label_string, input, model, dataset\n",
    "\n",
    "    def transform_embedding(embedding_list):\n",
    "        return np.array([tensor.item() for tensor in embedding_list])\n",
    "\n",
    "    df[\"embedding\"] = df[\"embedding\"].apply(transform_embedding)\n",
    "    df[\"label\"] = df[\"label\"].apply(lambda x: x.item())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_cpu = True\n",
    "models = {\n",
    "    \"ViT-Pretrained\": get_pretrained_vit,\n",
    "    \"ViT-Finetuned\": get_finetuned_vit,\n",
    "    \"EfN-Pretrained\": get_pretrained_efnet,\n",
    "    \"EfN-Finetuned\": get_finetuned_efnet,\n",
    "}\n",
    "\n",
    "# TODO(liamvdv): @robert: why filtered? Worauf sind die Dataset Stats?\n",
    "BRISTOL = Path(\n",
    "    \"/workspaces/gorillatracker/data/supervised/bristol/cross_encounter_validation/cropped_frames_square_filtered\"\n",
    ")\n",
    "SPAC = Path(\"/workspaces/gorillatracker/data/supervised/cxl_all/face_images_square\")\n",
    "datasets = {\n",
    "    \"Bristol\": BRISTOL,\n",
    "    \"SPAC\": SPAC,\n",
    "}\n",
    "dfs = []\n",
    "for model_name, get_model in models.items():\n",
    "    for dataset_name, dataset_path in datasets.items():\n",
    "        model = get_model()\n",
    "        if not model:\n",
    "            print(\"Skipping model\", model_name, \"for dataset\", dataset_name, \"Model not yet implemented.\")\n",
    "            continue\n",
    "        if on_cpu:\n",
    "            model = model.cpu()\n",
    "        df = get_df(model, dataset_path)\n",
    "        df[\"dataset\"] = dataset_name\n",
    "        df[\"model\"] = model_name\n",
    "        print(\"Appending\", model_name, dataset_name, f\"{len(df)} rows\")\n",
    "        dfs.append(df)\n",
    "\n",
    "        # Cleanup\n",
    "        del model  # and?: torch.cuda.empty_cache()\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "merged_df.to_pickle(\"merged.pkl\")\n",
    "print(\"done\")\n",
    "# vitf_spac = merged_df[(merged_df['model'] == 'ViT-Finetuned') & (merged_df['dataset'] == 'SPAC')]\n",
    "\n",
    "# model = get_moco_model()\n",
    "# bristol = get_df(model, BRISTOL)\n",
    "# # bristol[\"dataset\"] = \"bristol\"\n",
    "# # bristol[\"model\"] = \"ViT-Finetuned\" (fine tuned) (MoCo-ViT-DinoV2)\n",
    "# bristol.to_pickle(\"bristol.pkl\")\n",
    "# spac = get_df(model, SPAC)\n",
    "# # spac[\"dataset\"] = \"spac\"\n",
    "# # spac[\"model\"] = \"ViT-Finetuned\" (fine tuned)\n",
    "# spac.to_pickle(\"spac.pkl\")\n",
    "# # merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "# print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
