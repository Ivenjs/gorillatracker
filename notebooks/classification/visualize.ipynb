{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Usage\n",
    "mdf = pd.read_pickle(\"merged.pkl\")  # Load your DataFrame\n",
    "df = mdf[(mdf[\"model\"] == \"ViT-Finetuned\") & (mdf[\"dataset\"] == \"Bristol\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def visualize_cumulative_individual_distribution(name, df, figsize=(12, 6)):\n",
    "    \"\"\"\n",
    "    Visualize the cumulative percentage of individuals remaining at different\n",
    "    image count thresholds.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing a 'label' column.\n",
    "    figsize (tuple): Figure size in inches. Default is (12, 6).\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the plot.\n",
    "    \"\"\"\n",
    "    # Count the occurrences of each label\n",
    "    label_counts = df[\"label\"].value_counts()\n",
    "\n",
    "    # Calculate cumulative percentages\n",
    "    total_individuals = len(label_counts)\n",
    "    cumulative_percentages = [\n",
    "        (label_counts >= i).sum() / total_individuals * 100 for i in range(1, label_counts.max() + 1)\n",
    "    ]\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot(range(1, len(cumulative_percentages) + 1), cumulative_percentages, marker=\"o\")\n",
    "    ax.set_title(f\"{name} Cumulative Percentage of Individuals vs. Minimum Image Count\")\n",
    "    ax.set_xlabel(\"Minimum Number of Images per Individual\")\n",
    "    ax.set_ylabel(\"Percentage of Individuals Remaining\")\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Add description text to the plot\n",
    "    description = (\n",
    "        \"How any individuals remains at given minimum image size cutoff point? \\n This plot shows how many individuals remain in the dataset\"\n",
    "        \"as the minimum required number of images per individual increases.\"\n",
    "    )\n",
    "    ax.text(0.5, -0.15, description, transform=ax.transAxes, ha=\"center\", va=\"center\", fontsize=10)\n",
    "\n",
    "    # Add percentage labels at specific points\n",
    "    thresholds = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50]\n",
    "    for threshold in thresholds:\n",
    "        if threshold <= len(cumulative_percentages):\n",
    "            percentage = cumulative_percentages[threshold - 1]\n",
    "            ax.annotate(\n",
    "                f\"{percentage:.1f}%\", (threshold, percentage), textcoords=\"offset points\", xytext=(0, 10), ha=\"center\"\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print some additional statistics\n",
    "    print(\"Percentage of individuals remaining at specific thresholds:\")\n",
    "    for threshold in thresholds:\n",
    "        if threshold <= len(cumulative_percentages):\n",
    "            percentage = cumulative_percentages[threshold - 1]\n",
    "            print(f\"  â‰¥ {threshold} images: {percentage:.1f}%\")\n",
    "\n",
    "\n",
    "# 1. Distribution of labels with n number of images\n",
    "label_counts = df[\"label\"].value_counts()\n",
    "count_distribution = label_counts.value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "count_distribution.plot(kind=\"bar\")\n",
    "plt.title(\"Distribution of Number of Images per Individual\")\n",
    "plt.xlabel(\"Number of Images\")\n",
    "plt.ylabel(\"Number of Individuals\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "visualize_cumulative_individual_distribution(df[\"dataset\"].iloc[0], df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.io import output_notebook\n",
    "import colorcet as cc\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "def reduce_dimensions(embeddings, method=\"pca\", n_components=2, **kwargs):\n",
    "    \"\"\"\n",
    "    Reduce the dimensionality of the embeddings.\n",
    "\n",
    "    Args:\n",
    "    embeddings (np.array): The input embeddings.\n",
    "    method (str): The dimensionality reduction method ('pca' or 'tsne').\n",
    "    n_components (int): The number of dimensions to reduce to.\n",
    "    **kwargs: Additional arguments to pass to the dimensionality reduction method.\n",
    "\n",
    "    Returns:\n",
    "    np.array: The reduced embeddings.\n",
    "    \"\"\"\n",
    "    if method.lower() == \"pca\":\n",
    "        reducer = PCA(n_components=n_components, **kwargs)\n",
    "    elif method.lower() == \"tsne\":\n",
    "        reducer = TSNE(n_components=n_components, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be either 'pca' or 'tsne'\")\n",
    "\n",
    "    return reducer.fit_transform(embeddings)\n",
    "\n",
    "\n",
    "def image_to_base64(img):\n",
    "    \"\"\"Convert a PIL image to base64 string.\"\"\"\n",
    "    buffered = io.BytesIO()\n",
    "    img.save(buffered, format=\"JPEG\")\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "    return img_str\n",
    "\n",
    "\n",
    "def visualize_embeddings(df, method=\"pca\", n_components=2, **kwargs):\n",
    "    \"\"\"\n",
    "    Visualize embeddings using either PCA or t-SNE.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The input DataFrame containing embeddings and metadata.\n",
    "    method (str): The dimensionality reduction method ('pca' or 'tsne').\n",
    "    n_components (int): The number of dimensions to reduce to.\n",
    "    **kwargs: Additional arguments to pass to the dimensionality reduction method.\n",
    "\n",
    "    Returns:\n",
    "    bokeh.plotting.figure: The Bokeh figure object.\n",
    "    \"\"\"\n",
    "    # Perform dimensionality reduction\n",
    "    embeddings = np.vstack(df[\"embedding\"].values)\n",
    "    embeddings_2d = reduce_dimensions(embeddings, method, n_components, **kwargs)\n",
    "\n",
    "    # Create a color map\n",
    "    unique_labels = df[\"label\"].unique()\n",
    "    num_labels = len(unique_labels)\n",
    "    color_palette = cc.glasbey[:num_labels]\n",
    "    color_map = dict(zip(unique_labels, color_palette))\n",
    "\n",
    "    # Prepare data for Bokeh\n",
    "    data = {\n",
    "        \"x\": embeddings_2d[:, 0],\n",
    "        \"y\": embeddings_2d[:, 1],\n",
    "        \"color\": [color_map[label] for label in df[\"label\"]],\n",
    "        \"class\": df[\"label\"],\n",
    "        \"image\": [image_to_base64(img) for img in df[\"input\"]],\n",
    "    }\n",
    "\n",
    "    source = ColumnDataSource(data=data)\n",
    "\n",
    "    # Create the figure\n",
    "    p = figure(\n",
    "        width=1920,\n",
    "        height=1080,\n",
    "        title=f\"2D Projection of Classes using {method.upper()}\",\n",
    "        tools=\"pan,wheel_zoom,box_zoom,reset\",\n",
    "    )\n",
    "\n",
    "    # Add the scatter plot\n",
    "    p.scatter(x=\"x\", y=\"y\", size=12, fill_color=\"color\", line_color=\"black\", source=source, legend_field=\"class\")\n",
    "\n",
    "    # Add hover tool\n",
    "    hover = HoverTool(tooltips='<img src=\"data:image/jpeg;base64,@image\" width=\"128\" height=\"128\">')\n",
    "    p.add_tools(hover)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mdf[(mdf[\"model\"] == \"ViT-Pretrained\") & (mdf[\"dataset\"] == \"MNIST\")]\n",
    "fig = visualize_embeddings(df, method=\"pca\")\n",
    "show(fig)\n",
    "fig = visualize_embeddings(df, method=\"tsne\")\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mdf[(mdf[\"model\"] == \"Synthetic\") & (mdf[\"dataset\"] == \"Synthetic 20c 20n\")]\n",
    "fig = visualize_embeddings(df, method=\"pca\")\n",
    "show(fig)\n",
    "fig = visualize_embeddings(df, method=\"tsne\", perplexity=max(len(df[\"label\"].unique()), 30))\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mdf[(mdf[\"model\"] == \"ViT-Finetuned\") & (mdf[\"dataset\"] == \"Bristol\")]\n",
    "fig = visualize_embeddings(df, method=\"pca\")\n",
    "show(fig)\n",
    "fig = visualize_embeddings(df, method=\"tsne\", perplexity=max(len(df[\"label\"].unique()), 30))\n",
    "show(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
