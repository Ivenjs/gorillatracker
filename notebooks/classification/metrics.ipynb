{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "merged_df = pd.read_pickle(\"merged.pkl\")\n",
    "vitf_spac = merged_df[(merged_df[\"model\"] == \"ViT-Finetuned\") & (merged_df[\"dataset\"] == \"SPAC\")]\n",
    "df = vitf_spac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import calinski_harabasz_score, silhouette_score, davies_bouldin_score\n",
    "\n",
    "\n",
    "def compute_centroids(df):\n",
    "    \"\"\"\n",
    "    Compute centroids for each label group using the mean of all embeddings.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing 'label', 'label_string', and 'embedding' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing centroids for each label group.\n",
    "    \"\"\"\n",
    "    centroids = df.groupby([\"label\", \"label_string\"])[\"embedding\"].apply(lambda x: np.mean(np.vstack(x), axis=0))\n",
    "    centroid_df = pd.DataFrame({\"centroid\": centroids.values})\n",
    "    centroid_df[[\"label\", \"label_string\"]] = pd.DataFrame(centroids.index.tolist(), index=centroid_df.index)\n",
    "    return centroid_df\n",
    "\n",
    "\n",
    "def compute_iqr_centroids(df):\n",
    "    \"\"\"\n",
    "    Compute centroids for each label group using embeddings within the IQR.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing 'label', 'label_string', and 'embedding' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing IQR-based centroids for each label group.\n",
    "    \"\"\"\n",
    "\n",
    "    def iqr_mean(group):\n",
    "        embeddings = np.vstack(group)\n",
    "        q1 = np.percentile(embeddings, 25, axis=0)\n",
    "        q3 = np.percentile(embeddings, 75, axis=0)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "        mask = np.all((embeddings >= lower_bound) & (embeddings <= upper_bound), axis=1)\n",
    "        return np.mean(embeddings[mask], axis=0)\n",
    "\n",
    "    iqr_centroids = df.groupby([\"label\", \"label_string\"])[\"embedding\"].apply(iqr_mean)\n",
    "    iqr_centroid_df = pd.DataFrame({\"centroid\": iqr_centroids.values})\n",
    "    iqr_centroid_df[[\"label\", \"label_string\"]] = pd.DataFrame(iqr_centroids.index.tolist(), index=iqr_centroid_df.index)\n",
    "    return iqr_centroid_df\n",
    "\n",
    "\n",
    "def analyse_embedding_space(df) -> dict:\n",
    "    centroid_df = compute_centroids(df)\n",
    "\n",
    "    for label in centroid_df[\"label\"]:\n",
    "        centroid = centroid_df[centroid_df[\"label\"] == label][\"centroid\"].values[0]\n",
    "        embeddings = df[df[\"label\"] == label][\"embedding\"].tolist()\n",
    "        distances = cdist(embeddings, [centroid])\n",
    "        min_distance = np.min(distances)\n",
    "        max_distance = np.max(distances)\n",
    "        avg_distance = np.mean(distances)\n",
    "        centroid_df.loc[centroid_df[\"label\"] == label, \"min_distance\"] = min_distance\n",
    "        centroid_df.loc[centroid_df[\"label\"] == label, \"max_distance\"] = max_distance\n",
    "        centroid_df.loc[centroid_df[\"label\"] == label, \"avg_distance\"] = avg_distance\n",
    "\n",
    "    all_embeddings = df[\"embedding\"].tolist()\n",
    "    all_dist = cdist(all_embeddings, all_embeddings)\n",
    "\n",
    "    # Create a mask to exclude the diagonal (self-distances)\n",
    "    mask = ~np.eye(all_dist.shape[0], dtype=bool)\n",
    "\n",
    "    all_centroid_dist = cdist(centroid_df[\"centroid\"].tolist(), centroid_df[\"centroid\"].tolist())\n",
    "    centroid_mask = ~np.eye(all_centroid_dist.shape[0], dtype=bool)\n",
    "\n",
    "    # Convert embeddings to a numpy array for sklearn functions\n",
    "    embeddings_array = np.array(all_embeddings)\n",
    "    labels_array = df[\"label\"].values\n",
    "\n",
    "    # Calinski-Harabasz Index\n",
    "    ch_index = calinski_harabasz_score(embeddings_array, labels_array)\n",
    "\n",
    "    # Within-cluster Sum of Squares (WCSS)\n",
    "    wcss = sum(centroid_df[\"avg_distance\"] ** 2 * centroid_df[\"label\"].map(df[\"label\"].value_counts()))\n",
    "\n",
    "    # Silhouette Coefficient\n",
    "    silhouette_avg = silhouette_score(embeddings_array, labels_array)\n",
    "\n",
    "    # Davies-Bouldin Index\n",
    "    db_index = davies_bouldin_score(embeddings_array, labels_array)\n",
    "\n",
    "    # Dunn Index\n",
    "    min_inter_cluster_distance = np.min(all_centroid_dist[centroid_mask])\n",
    "    max_intra_cluster_distance = centroid_df[\"max_distance\"].max()\n",
    "    dunn_index = min_inter_cluster_distance / max_intra_cluster_distance\n",
    "\n",
    "    metrics = {\n",
    "        \"global_max_dist\": np.max(all_dist[mask]),\n",
    "        \"global_min_dist\": np.min(all_dist[mask]),\n",
    "        \"global_avg_dist\": np.mean(all_dist[mask]),\n",
    "        \"global_std_dist\": np.std(all_dist[mask]),\n",
    "        \"intra_min_dist\": centroid_df[\"min_distance\"].min(),\n",
    "        \"intra_max_dist\": centroid_df[\"max_distance\"].max(),\n",
    "        \"intra_avg_dist\": centroid_df[\"avg_distance\"].mean(),\n",
    "        \"intra_std_dist\": centroid_df[\"avg_distance\"].std(),\n",
    "        \"inter_min_dist\": np.min(all_centroid_dist[centroid_mask]),\n",
    "        \"inter_max_dist\": np.max(all_centroid_dist[centroid_mask]),\n",
    "        \"inter_avg_dist\": np.mean(all_centroid_dist[centroid_mask]),\n",
    "        \"inter_std_dist\": np.std(all_centroid_dist[centroid_mask]),\n",
    "        \"calinski_harabasz_index\": ch_index,\n",
    "        \"wcss\": wcss,\n",
    "        \"silhouette_coefficient\": silhouette_avg,\n",
    "        \"davies_bouldin_index\": db_index,\n",
    "        \"dunn_index\": dunn_index,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "formatted_names = {\n",
    "    \"global_max_dist\": \"Pairwise Max Distance\",\n",
    "    \"global_min_dist\": \"Pairwise Min Distance\",\n",
    "    \"global_avg_dist\": \"Pairwise Avg Distance\",\n",
    "    \"global_std_dist\": \"Pairwise Std Dev of Distances\",\n",
    "    \"intra_min_dist\": \"Within-Cluster Min Distance\",\n",
    "    \"intra_max_dist\": \"Within-Cluster Max Distance\",\n",
    "    \"intra_avg_dist\": \"Within-Cluster Avg Distance\",\n",
    "    \"intra_std_dist\": \"Within-Cluster Std Dev of Distances\",\n",
    "    \"inter_min_dist\": \"Between-Cluster Min Distance\",\n",
    "    \"inter_max_dist\": \"Between-Cluster Max Distance\",\n",
    "    \"inter_avg_dist\": \"Between-Cluster Avg Distance\",\n",
    "    \"inter_std_dist\": \"Between-Cluster Std Dev of Distances\",\n",
    "    \"calinski_harabasz_index\": \"Calinski-Harabasz Index\",\n",
    "    \"wcss\": \"Within-Cluster Sum of Squares\",\n",
    "    \"silhouette_coefficient\": \"Silhouette Coefficient\",\n",
    "    \"davies_bouldin_index\": \"Davies-Bouldin Index\",\n",
    "    \"dunn_index\": \"Dunn Index\",\n",
    "}\n",
    "\n",
    "\n",
    "def format_metrics(metrics):\n",
    "    global formatted_names\n",
    "    print(\"Cluster Evaluation Metrics:\")\n",
    "    print(\"=\" * 50)\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{formatted_names[key]}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = analyse_embedding_space(df)\n",
    "format_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_latex_table(metrics, formatted_names):\n",
    "    latex_table = r\"\"\"\n",
    "\\begin{table}\n",
    "    \\centering\n",
    "    \\resizebox{0.8\\paperwidth}{!}{\n",
    "    \\begin{tabular}{l *{8}{c}}\n",
    "    \\toprule\n",
    "    & \\multicolumn{2}{c}{Bristol} & \\multicolumn{2}{c}{SPAC} & \\multicolumn{2}{c}{Bristol} & \\multicolumn{2}{c}{SPAC} \\\\\n",
    "    \\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7} \\cmidrule(lr){8-9}\n",
    "    Metric & ViT-F & ViT-P & ViT-F & ViT-P & EfN-F & EfN-P & EfN-F & EfN-P \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "    for metric, formatted_name in formatted_names.items():\n",
    "        row = f\"{formatted_name} \"\n",
    "        for model_prefix in [\"ViT-\", \"EfN-\"]:\n",
    "            for dataset in [\"Bristol\", \"SPAC\"]:\n",
    "                for model_suffix in [\"F\", \"P\"]:\n",
    "                    model = f\"{model_prefix}{model_suffix}\"\n",
    "                    value = metrics.get((model, dataset), {}).get(metric, \"-\")\n",
    "                    if isinstance(value, float):\n",
    "                        row += f\"& {value:.2f} \"\n",
    "                    else:\n",
    "                        row += f\"& {value} \"\n",
    "        row += r\"\\\\\"\n",
    "        latex_table += row + \"\\n\"\n",
    "\n",
    "    latex_table += r\"\"\"    \\bottomrule\n",
    "    \\end{tabular}\n",
    "    }\n",
    "    \\caption{Metrics comparison across models and datasets.}\n",
    "    \\label{tab:metrics-comparison}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    return latex_table\n",
    "\n",
    "\n",
    "df = merged_df\n",
    "actual_metrics = {\n",
    "    (\"ViT-F\", \"SPAC\"): analyse_embedding_space(df[(df[\"model\"] == \"ViT-Finetuned\") & (df[\"dataset\"] == \"SPAC\")]),\n",
    "    (\"ViT-P\", \"SPAC\"): analyse_embedding_space(df[(df[\"model\"] == \"ViT-Pretrained\") & (df[\"dataset\"] == \"SPAC\")]),\n",
    "    # ('EfN-F', 'SPAC'): analyse_embedding_space(df[(df['model'] == 'EfN-Finetuned') & (df['dataset'] == 'SPAC')]),\n",
    "    (\"EfN-P\", \"SPAC\"): analyse_embedding_space(df[(df[\"model\"] == \"EfN-Pretrained\") & (df[\"dataset\"] == \"SPAC\")]),\n",
    "    (\"ViT-F\", \"Bristol\"): analyse_embedding_space(df[(df[\"model\"] == \"ViT-Finetuned\") & (df[\"dataset\"] == \"Bristol\")]),\n",
    "    (\"ViT-P\", \"Bristol\"): analyse_embedding_space(df[(df[\"model\"] == \"ViT-Pretrained\") & (df[\"dataset\"] == \"Bristol\")]),\n",
    "    # ('EfN-F', 'Bristol'): analyse_embedding_space(df[(df['model'] == 'EfN-Finetuned') & (df['dataset'] == 'Bristol')]),\n",
    "    (\"EfN-P\", \"Bristol\"): analyse_embedding_space(df[(df[\"model\"] == \"EfN-Pretrained\") & (df[\"dataset\"] == \"Bristol\")]),\n",
    "}\n",
    "\n",
    "print(create_latex_table(actual_metrics, formatted_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
