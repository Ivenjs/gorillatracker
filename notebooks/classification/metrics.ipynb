{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "merged_df = pd.read_pickle(\"merged.pkl\")\n",
    "vitf_spac = merged_df[(merged_df[\"model\"] == \"ViT-Finetuned\") & (merged_df[\"dataset\"] == \"SPAC\")]\n",
    "df = vitf_spac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import calinski_harabasz_score, silhouette_score, davies_bouldin_score\n",
    "\n",
    "\n",
    "def compute_centroids(df):\n",
    "    \"\"\"\n",
    "    Compute centroids for each label group using the mean of all embeddings.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing 'label', 'label_string', and 'embedding' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing centroids for each label group.\n",
    "    \"\"\"\n",
    "    centroids = df.groupby([\"label\", \"label_string\"])[\"embedding\"].apply(lambda x: np.mean(np.vstack(x), axis=0))\n",
    "    centroid_df = pd.DataFrame({\"centroid\": centroids.values})\n",
    "    centroid_df[[\"label\", \"label_string\"]] = pd.DataFrame(centroids.index.tolist(), index=centroid_df.index)\n",
    "    return centroid_df\n",
    "\n",
    "\n",
    "def compute_iqr_centroids(df):\n",
    "    \"\"\"\n",
    "    Compute centroids for each label group using embeddings within the IQR.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing 'label', 'label_string', and 'embedding' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing IQR-based centroids for each label group.\n",
    "    \"\"\"\n",
    "\n",
    "    def iqr_mean(group):\n",
    "        embeddings = np.vstack(group)\n",
    "        q1 = np.percentile(embeddings, 25, axis=0)\n",
    "        q3 = np.percentile(embeddings, 75, axis=0)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "        mask = np.all((embeddings >= lower_bound) & (embeddings <= upper_bound), axis=1)\n",
    "        return np.mean(embeddings[mask], axis=0)\n",
    "\n",
    "    iqr_centroids = df.groupby([\"label\", \"label_string\"])[\"embedding\"].apply(iqr_mean)\n",
    "    iqr_centroid_df = pd.DataFrame({\"centroid\": iqr_centroids.values})\n",
    "    iqr_centroid_df[[\"label\", \"label_string\"]] = pd.DataFrame(iqr_centroids.index.tolist(), index=iqr_centroid_df.index)\n",
    "    return iqr_centroid_df\n",
    "\n",
    "\n",
    "def analyse_embedding_space(df) -> dict:\n",
    "    centroid_df = compute_centroids(df)\n",
    "\n",
    "    for label in centroid_df[\"label\"]:\n",
    "        centroid = centroid_df[centroid_df[\"label\"] == label][\"centroid\"].values[0]\n",
    "        embeddings = df[df[\"label\"] == label][\"embedding\"].tolist()\n",
    "        distances = cdist(embeddings, [centroid])\n",
    "        min_distance = np.min(distances)\n",
    "        max_distance = np.max(distances)\n",
    "        avg_distance = np.mean(distances)\n",
    "        centroid_df.loc[centroid_df[\"label\"] == label, \"min_distance\"] = min_distance\n",
    "        centroid_df.loc[centroid_df[\"label\"] == label, \"max_distance\"] = max_distance\n",
    "        centroid_df.loc[centroid_df[\"label\"] == label, \"avg_distance\"] = avg_distance\n",
    "\n",
    "    all_dist = cdist(df[\"embedding\"].tolist(), df[\"embedding\"].tolist())\n",
    "    all_centroid_dist = cdist(centroid_df[\"centroid\"].tolist(), centroid_df[\"centroid\"].tolist())\n",
    "\n",
    "    # Convert embeddings to a numpy array for sklearn functions\n",
    "    embeddings_array = np.array(df[\"embedding\"].tolist())\n",
    "    labels_array = df[\"label\"].values\n",
    "\n",
    "    # Calinski-Harabasz Index\n",
    "    ch_index = calinski_harabasz_score(embeddings_array, labels_array)\n",
    "\n",
    "    # Within-cluster Sum of Squares (WCSS)\n",
    "    wcss = sum(centroid_df[\"avg_distance\"] ** 2 * centroid_df[\"label\"].map(df[\"label\"].value_counts()))\n",
    "\n",
    "    # Silhouette Coefficient\n",
    "    silhouette_avg = silhouette_score(embeddings_array, labels_array)\n",
    "\n",
    "    # Davies-Bouldin Index\n",
    "    db_index = davies_bouldin_score(embeddings_array, labels_array)\n",
    "\n",
    "    # Dunn Index\n",
    "    min_inter_cluster_distance = np.min(all_centroid_dist[all_centroid_dist > 0])\n",
    "    max_intra_cluster_distance = centroid_df[\"max_distance\"].max()\n",
    "    dunn_index = min_inter_cluster_distance / max_intra_cluster_distance\n",
    "\n",
    "    metrics = {\n",
    "        \"global_max_dist\": np.max(all_dist),\n",
    "        \"global_min_dist\": np.min(all_dist),\n",
    "        \"global_avg_dist\": np.mean(all_dist),\n",
    "        \"global_std_dist\": np.std(all_dist),\n",
    "        \"intra_min_dist\": centroid_df[\"min_distance\"].min(),\n",
    "        \"intra_max_dist\": centroid_df[\"max_distance\"].max(),\n",
    "        \"intra_avg_dist\": centroid_df[\"avg_distance\"].mean(),\n",
    "        \"intra_std_dist\": centroid_df[\"avg_distance\"].std(),\n",
    "        \"inter_min_dist\": np.min(all_centroid_dist),\n",
    "        \"inter_max_dist\": np.max(all_centroid_dist),\n",
    "        \"inter_avg_dist\": np.mean(all_centroid_dist),\n",
    "        \"inter_std_dist\": np.std(all_centroid_dist),\n",
    "        \"calinski_harabasz_index\": ch_index,\n",
    "        \"wcss\": wcss,\n",
    "        \"silhouette_coefficient\": silhouette_avg,\n",
    "        \"davies_bouldin_index\": db_index,\n",
    "        \"dunn_index\": dunn_index,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def format_metrics(metrics):\n",
    "    formatted_names = {\n",
    "        \"global_max_dist\": \"Global Maximum Embedding Distance\",\n",
    "        \"global_min_dist\": \"Global Minimum Embedding Distance\",\n",
    "        \"global_avg_dist\": \"Global Average Embedding Distance\",\n",
    "        \"global_std_dist\": \"Global Standard Deviation of Embedding Distance\",\n",
    "        \"intra_min_dist\": \"Minimum Intra-Cluster Distance\",\n",
    "        \"intra_max_dist\": \"Maximum Intra-Cluster Distance\",\n",
    "        \"intra_avg_dist\": \"Average Intra-Cluster Distance\",\n",
    "        \"intra_std_dist\": \"Standard Deviation of Intra-Cluster Distance\",\n",
    "        \"inter_min_dist\": \"Minimum Inter-Cluster Distance\",\n",
    "        \"inter_max_dist\": \"Maximum Inter-Cluster Distance\",\n",
    "        \"inter_avg_dist\": \"Average Inter-Cluster Distance\",\n",
    "        \"inter_std_dist\": \"Standard Deviation of Inter-Cluster Distance\",\n",
    "        \"calinski_harabasz_index\": \"Calinski-Harabasz Index\",\n",
    "        \"wcss\": \"Within-Cluster Sum of Squares (WCSS)\",\n",
    "        \"silhouette_coefficient\": \"Silhouette Coefficient\",\n",
    "        \"davies_bouldin_index\": \"Davies-Bouldin Index\",\n",
    "        \"dunn_index\": \"Dunn Index\",\n",
    "    }\n",
    "\n",
    "    print(\"Cluster Evaluation Metrics:\")\n",
    "    print(\"=\" * 50)\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{formatted_names[key]}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = analyse_embedding_space(df)\n",
    "format_metrics(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
