{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def format_value(value):\n",
    "    if pd.isna(value) or value == \"nan\":\n",
    "        return \"nan\"\n",
    "    elif isinstance(value, (int, float)):\n",
    "        return f\"{value:.3f}\"\n",
    "    else:\n",
    "        return str(value)\n",
    "\n",
    "\n",
    "def generate_single_embedding_space_graphic(df, dataset, model):\n",
    "    df = df.copy()\n",
    "\n",
    "    # First, filter the DataFrame\n",
    "    spac_max3_vit_df = df[(df[\"dataset\"] == dataset) & (df[\"model\"] == model)]\n",
    "\n",
    "    # List to store the summary of metrics\n",
    "    metrics_summary = []\n",
    "\n",
    "    # List of algorithms to check\n",
    "    algorithms_to_check = spac_max3_vit_df[\"algorithm\"].unique()\n",
    "\n",
    "    # Iterate over each algorithm\n",
    "    for algorithm in algorithms_to_check:\n",
    "        # Filter DataFrame for the current algorithm\n",
    "        algorithm_df = spac_max3_vit_df[spac_max3_vit_df[\"algorithm\"] == algorithm]\n",
    "\n",
    "        # Get the rows with max silhouette score, max dunn index, min davies-bouldin index, and max calinski-harabasz index\n",
    "        max_silhouette_row = algorithm_df.loc[algorithm_df[\"silhouette_coefficient\"].idxmax()]\n",
    "        max_dunn_row = algorithm_df.loc[algorithm_df[\"dunn_index\"].idxmax()]\n",
    "        min_davies_bouldin_row = algorithm_df.loc[algorithm_df[\"davies_bouldin_index\"].idxmin()]\n",
    "        max_calinski_harabasz_row = algorithm_df.loc[algorithm_df[\"calinski_harabasz_index\"].idxmax()]\n",
    "\n",
    "        # Add rows to the metrics summary\n",
    "        metrics_summary.extend(\n",
    "            [\n",
    "                [\n",
    "                    \"Silhouette Score (max)\",\n",
    "                    algorithm,\n",
    "                    max_silhouette_row[\"adjusted_rand_score\"],\n",
    "                    max_silhouette_row[\"homogeneity_score\"],\n",
    "                    max_silhouette_row[\"completeness_score\"],\n",
    "                    max_silhouette_row[\"v_measure_score\"],\n",
    "                    max_silhouette_row[\"n_clusters\"],\n",
    "                ],\n",
    "                [\n",
    "                    \"Dunn Index (max)\",\n",
    "                    algorithm,\n",
    "                    max_dunn_row[\"adjusted_rand_score\"],\n",
    "                    max_dunn_row[\"homogeneity_score\"],\n",
    "                    max_dunn_row[\"completeness_score\"],\n",
    "                    max_dunn_row[\"v_measure_score\"],\n",
    "                    max_dunn_row[\"n_clusters\"],\n",
    "                ],\n",
    "                [\n",
    "                    \"Davies-Bouldin Index (min)\",\n",
    "                    algorithm,\n",
    "                    min_davies_bouldin_row[\"adjusted_rand_score\"],\n",
    "                    min_davies_bouldin_row[\"homogeneity_score\"],\n",
    "                    min_davies_bouldin_row[\"completeness_score\"],\n",
    "                    min_davies_bouldin_row[\"v_measure_score\"],\n",
    "                    min_davies_bouldin_row[\"n_clusters\"],\n",
    "                ],\n",
    "                [\n",
    "                    \"Calinski-Harabasz Index (max)\",\n",
    "                    algorithm,\n",
    "                    max_calinski_harabasz_row[\"adjusted_rand_score\"],\n",
    "                    max_calinski_harabasz_row[\"homogeneity_score\"],\n",
    "                    max_calinski_harabasz_row[\"completeness_score\"],\n",
    "                    max_calinski_harabasz_row[\"v_measure_score\"],\n",
    "                    max_calinski_harabasz_row[\"n_clusters\"],\n",
    "                ],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Convert to DataFrame for easy display\n",
    "    return pd.DataFrame(\n",
    "        metrics_summary,\n",
    "        columns=[\n",
    "            \"Approach\",\n",
    "            \"Algorithm\",\n",
    "            \"Rand Score\",\n",
    "            \"Homogeneity\",\n",
    "            \"Completeness\",\n",
    "            \"V-Measure\",\n",
    "            \"n_clusters\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_latex_table(df, dataset, model, ref=\"tab:clustering-metrics-spac\", is_cosine=False):\n",
    "    latex_code = [\n",
    "        r\"\\begin{table}[H]\",\n",
    "        r\"    \\centering\",\n",
    "        r\"    \\resizebox{\\textwidth}{!}{%\",\n",
    "        r\"    \\begin{tabular}{llccccc}\",\n",
    "        r\"    \\toprule\",\n",
    "        r\"    \\multicolumn{2}{l}{Approaches} & \\multicolumn{4}{c}{Metrics} \\\\\",\n",
    "        r\"     \\cmidrule(lr){3-6}\",\n",
    "        r\"    & & ARI & Homogeneity & Completeness & V-Measure & Clusters Found \\\\\",\n",
    "        r\"    \\midrule\",\n",
    "    ]\n",
    "\n",
    "    # Filter out \"HDBSCAN\" rows to append later\n",
    "    hdbscan_rows = df[df[\"Algorithm\"] == \"HDBSCAN\"]\n",
    "    df = df[df[\"Algorithm\"] != \"HDBSCAN\"]\n",
    "\n",
    "    for approach in df[\"Approach\"].unique():\n",
    "        latex_code.append(f\"    \\multicolumn{{7}}{{l}}{{\\\\textbf{{{approach}}}}} \\\\\\\\\")\n",
    "        group = df[df[\"Approach\"] == approach]\n",
    "        for _, row in group.iterrows():\n",
    "            formatted_values = [\n",
    "                format_value(row[\"Rand Score\"]),\n",
    "                format_value(row[\"Homogeneity\"]),\n",
    "                format_value(row[\"Completeness\"]),\n",
    "                format_value(row[\"V-Measure\"]),\n",
    "                str(row[\"n_clusters\"]),\n",
    "            ]\n",
    "            latex_code.append(f\"    & {row['Algorithm']} & {' & '.join(formatted_values)} \\\\\\\\\")\n",
    "        if approach != df[\"Approach\"].unique()[-1]:\n",
    "            latex_code.append(r\"    \\midrule\")\n",
    "\n",
    "    # Add the \"HDBSCAN\" row at the end with multicolumn \"Any\"\n",
    "    if not hdbscan_rows.empty:\n",
    "        latex_code.append(r\"    \\midrule\")\n",
    "        latex_code.append(r\"    \\multicolumn{7}{l}{\\textbf{Any}} \\\\\")\n",
    "        for _, row in hdbscan_rows[:1].iterrows():\n",
    "            formatted_values = [\n",
    "                format_value(row[\"Rand Score\"]),\n",
    "                format_value(row[\"Homogeneity\"]),\n",
    "                format_value(row[\"Completeness\"]),\n",
    "                format_value(row[\"V-Measure\"]),\n",
    "                str(row[\"n_clusters\"]),\n",
    "            ]\n",
    "            latex_code.append(f\"    & HDBSCAN & {' & '.join(formatted_values)} \\\\\\\\\")\n",
    "\n",
    "    latex_code.extend(\n",
    "        [\n",
    "            r\"    \\bottomrule\",\n",
    "            r\"    \\end{tabular}%\",\n",
    "            r\"    }\",\n",
    "            (\n",
    "                r\"    \\caption{Comparison of Clustering Approaches and Algorithms across Various Metrics. Dataset is \"\n",
    "                + dataset\n",
    "                + \" and Model is \"\n",
    "                + model\n",
    "                + \" (Cosine Similarity)\"\n",
    "                if is_cosine\n",
    "                else \" (Euclidean Distance)\" + \"}\"\n",
    "            ),\n",
    "            r\"    \\label{\" + ref + \"}\",\n",
    "            r\"\\end{table}\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return \"\\n\".join(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\resizebox{\\textwidth}{!}{%\n",
      "    \\begin{tabular}{llccccc}\n",
      "    \\toprule\n",
      "    \\multicolumn{2}{l}{Approaches} & \\multicolumn{4}{c}{Metrics} \\\\\n",
      "     \\cmidrule(lr){3-6}\n",
      "    & & ARI & Homogeneity & Completeness & V-Measure & Clusters Found \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Silhouette Score (max)}} \\\\\n",
      "    & KMeans & 0.221 & 0.970 & 0.706 & 0.817 & 453 \\\\\n",
      "    & AgglomerativeClustering & 0.221 & 0.987 & 0.710 & 0.826 & 463 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Dunn Index (max)}} \\\\\n",
      "    & KMeans & 0.132 & 0.995 & 0.668 & 0.799 & 698 \\\\\n",
      "    & AgglomerativeClustering & 0.119 & 0.999 & 0.666 & 0.799 & 703 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Davies-Bouldin Index (min)}} \\\\\n",
      "    & KMeans & 0.127 & 0.997 & 0.665 & 0.798 & 718 \\\\\n",
      "    & AgglomerativeClustering & 0.113 & 0.999 & 0.663 & 0.797 & 718 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Calinski-Harabasz Index (max)}} \\\\\n",
      "    & KMeans & 0.047 & 0.161 & 0.629 & 0.256 & 3 \\\\\n",
      "    & AgglomerativeClustering & 0.049 & 0.195 & 0.819 & 0.315 & 3 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Any}} \\\\\n",
      "    & HDBSCAN & -0.001 & 0.045 & 0.597 & 0.084 & 2 \\\\\n",
      "    \\bottomrule\n",
      "    \\end{tabular}%\n",
      "    }\n",
      "    \\caption{Comparison of Clustering Approaches and Algorithms across Various Metrics. Dataset is SPAC+min3 and Model is ViT-Finetuned (Cosine Similarity)\n",
      "    \\label{tab:clustering-metrics-spac-euclidean}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "def generate(\n",
    "    ref: str = \"tab:clustering-metrics-spac\",\n",
    "    is_cosine: bool = False,\n",
    "    dataset: str = \"SPAC+min3\",\n",
    "    model: str = \"ViT-Finetuned\",\n",
    "):\n",
    "    metrics_df = pd.read_pickle(\n",
    "        f\"/workspaces/gorillatracker/sep29_clustering_results{'_cosine' if is_cosine else '_euclidean'}.pkl\"\n",
    "    )\n",
    "    metrics_summary_df = generate_single_embedding_space_graphic(metrics_df, dataset, model)\n",
    "    print(generate_latex_table(metrics_summary_df, dataset, model, ref, is_cosine=True))\n",
    "\n",
    "\n",
    "generate(\"tab:clustering-metrics-spac-euclidean\", is_cosine=False, dataset=\"SPAC+min3\", model=\"ViT-Finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\resizebox{\\textwidth}{!}{%\n",
      "    \\begin{tabular}{llccccc}\n",
      "    \\toprule\n",
      "    \\multicolumn{2}{l}{Approaches} & \\multicolumn{4}{c}{Metrics} \\\\\n",
      "     \\cmidrule(lr){3-6}\n",
      "    & & ARI & Homogeneity & Completeness & V-Measure & Clusters Found \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Silhouette Score (max)}} \\\\\n",
      "    & KMeans & 0.148 & 0.981 & 0.676 & 0.800 & 583 \\\\\n",
      "    & AgglomerativeClustering & 0.390 & 0.994 & 0.743 & 0.850 & 463 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Dunn Index (max)}} \\\\\n",
      "    & KMeans & 0.117 & 0.989 & 0.661 & 0.793 & 698 \\\\\n",
      "    & AgglomerativeClustering & 0.196 & 1.000 & 0.681 & 0.810 & 693 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Davies-Bouldin Index (min)}} \\\\\n",
      "    & KMeans & 0.111 & 0.991 & 0.659 & 0.792 & 718 \\\\\n",
      "    & AgglomerativeClustering & 0.188 & 1.000 & 0.677 & 0.807 & 718 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Calinski-Harabasz Index (max)}} \\\\\n",
      "    & KMeans & 0.040 & 0.156 & 0.613 & 0.249 & 3 \\\\\n",
      "    & AgglomerativeClustering & 0.082 & 0.288 & 0.847 & 0.430 & 8 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Any}} \\\\\n",
      "    & HDBSCAN & -0.001 & 0.037 & 0.649 & 0.070 & 2 \\\\\n",
      "    \\bottomrule\n",
      "    \\end{tabular}%\n",
      "    }\n",
      "    \\caption{Comparison of Clustering Approaches and Algorithms across Various Metrics. Dataset is SPAC+min3 and Model is ViT-Finetuned (Cosine Similarity)\n",
      "    \\label{tab:clustering-metrics-spac-cosine}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "generate(\"tab:clustering-metrics-spac-cosine\", is_cosine=True, dataset=\"SPAC+min3\", model=\"ViT-Finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\resizebox{\\textwidth}{!}{%\n",
      "    \\begin{tabular}{llccccc}\n",
      "    \\toprule\n",
      "    \\multicolumn{2}{l}{Approaches} & \\multicolumn{4}{c}{Metrics} \\\\\n",
      "     \\cmidrule(lr){3-6}\n",
      "    & & ARI & Homogeneity & Completeness & V-Measure & Clusters Found \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Silhouette Score (max)}} \\\\\n",
      "    & KMeans & 0.027 & 0.929 & 0.333 & 0.490 & 210 \\\\\n",
      "    & AgglomerativeClustering & 0.035 & 0.064 & 0.240 & 0.101 & 3 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Dunn Index (max)}} \\\\\n",
      "    & KMeans & 0.003 & 1.000 & 0.318 & 0.483 & 355 \\\\\n",
      "    & AgglomerativeClustering & 0.001 & 1.000 & 0.316 & 0.481 & 365 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Davies-Bouldin Index (min)}} \\\\\n",
      "    & KMeans & 0.000 & 1.000 & 0.315 & 0.480 & 370 \\\\\n",
      "    & AgglomerativeClustering & 0.000 & 1.000 & 0.315 & 0.480 & 370 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Calinski-Harabasz Index (max)}} \\\\\n",
      "    & KMeans & 0.087 & 0.132 & 0.185 & 0.154 & 4 \\\\\n",
      "    & AgglomerativeClustering & 0.035 & 0.064 & 0.240 & 0.101 & 3 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Any}} \\\\\n",
      "    & HDBSCAN & 0.063 & 0.080 & 0.241 & 0.120 & 2 \\\\\n",
      "    \\bottomrule\n",
      "    \\end{tabular}%\n",
      "    }\n",
      "    \\caption{Comparison of Clustering Approaches and Algorithms across Various Metrics. Dataset is Bristol and Model is ViT-Finetuned (Cosine Similarity)\n",
      "    \\label{tab:clustering-metrics-bristol-cosine}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "generate(\"tab:clustering-metrics-bristol-cosine\", is_cosine=True, dataset=\"Bristol\", model=\"ViT-Finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\resizebox{\\textwidth}{!}{%\n",
      "    \\begin{tabular}{llccccc}\n",
      "    \\toprule\n",
      "    \\multicolumn{2}{l}{Approaches} & \\multicolumn{4}{c}{Metrics} \\\\\n",
      "     \\cmidrule(lr){3-6}\n",
      "    & & ARI & Homogeneity & Completeness & V-Measure & Clusters Found \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Silhouette Score (max)}} \\\\\n",
      "    & KMeans & 0.031 & 0.981 & 0.346 & 0.511 & 235 \\\\\n",
      "    & AgglomerativeClustering & 0.041 & 0.966 & 0.354 & 0.518 & 190 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Dunn Index (max)}} \\\\\n",
      "    & KMeans & 0.002 & 1.000 & 0.317 & 0.482 & 360 \\\\\n",
      "    & AgglomerativeClustering & 0.001 & 1.000 & 0.316 & 0.481 & 365 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Davies-Bouldin Index (min)}} \\\\\n",
      "    & KMeans & 0.000 & 1.000 & 0.315 & 0.480 & 370 \\\\\n",
      "    & AgglomerativeClustering & 0.000 & 1.000 & 0.315 & 0.480 & 370 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Calinski-Harabasz Index (max)}} \\\\\n",
      "    & KMeans & 0.071 & 0.102 & 0.178 & 0.129 & 3 \\\\\n",
      "    & AgglomerativeClustering & 0.075 & 0.144 & 0.270 & 0.188 & 3 \\\\\n",
      "    \\midrule\n",
      "    \\multicolumn{7}{l}{\\textbf{Any}} \\\\\n",
      "    & HDBSCAN & 0.024 & 0.045 & 0.303 & 0.079 & 2 \\\\\n",
      "    \\bottomrule\n",
      "    \\end{tabular}%\n",
      "    }\n",
      "    \\caption{Comparison of Clustering Approaches and Algorithms across Various Metrics. Dataset is Bristol and Model is ViT-Finetuned (Cosine Similarity)\n",
      "    \\label{tab:clustering-metrics-bristol-euclidean}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "generate(\"tab:clustering-metrics-bristol-euclidean\", is_cosine=False, dataset=\"Bristol\", model=\"ViT-Finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
