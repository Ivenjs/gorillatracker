{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports / Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from gorillatracker.data.builder import build_onelet\n",
    "\n",
    "import logging\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Any, Literal\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from wildlife_datasets import datasets, loader\n",
    "\n",
    "import gorillatracker.type_helper as gtypes\n",
    "from gorillatracker.data.contrastive_sampler import ContrastiveImage, ContrastiveSampler, FlatNlet\n",
    "from gorillatracker.data.nlet import NletDataset, group_images_by_label\n",
    "from gorillatracker.type_helper import Id, Label, Nlet\n",
    "from gorillatracker.utils.labelencoder import LabelEncoder\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "params = {\n",
    "    \"font.size\": 10,\n",
    "    \"font.family\": \"serif\",\n",
    "}\n",
    "\n",
    "\n",
    "matplotlib.rcParams.update(params)\n",
    "\n",
    "import logging\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Any, Literal\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from wildlife_datasets import datasets, loader\n",
    "\n",
    "import gorillatracker.type_helper as gtypes\n",
    "from gorillatracker.data.contrastive_sampler import ContrastiveImage, ContrastiveSampler, FlatNlet\n",
    "from gorillatracker.data.nlet import NletDataset, group_images_by_label\n",
    "from gorillatracker.type_helper import Id, Label, Nlet\n",
    "from gorillatracker.utils.labelencoder import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from gorillatracker.transform_utils import SquarePad\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def get_ds_dfs(\n",
    "    use_primates: bool = True, train_factor: float = 0.7, val_factor: float = 0.15, test_factor: float = 0.15\n",
    ") -> pd.DataFrame:\n",
    "    rng = random.Random(42)\n",
    "    dfs = []\n",
    "\n",
    "    dataset_names = datasets.names_primates if use_primates else datasets.names_all\n",
    "\n",
    "    for ds_cls in dataset_names:\n",
    "        name = str(ds_cls).split(\".\")[-1][:-2]\n",
    "        if name.endswith(\"v2\"):\n",
    "            name = name[:-2]\n",
    "\n",
    "        if name in {\n",
    "            \"AAUZebraFish\",\n",
    "            \"GreenSeaTurtles\",\n",
    "            \"Drosophila\",\n",
    "            \"SMALST\",\n",
    "            \"AerialCattle2017\",  # DATA off (too big here -> prob video processing needed)\n",
    "            \"PolarBearVidID\",  # DATA off\n",
    "            \"SealIDSegmented\",  # no segmentation\n",
    "            \"BirdIndividualID\",  # License: None\n",
    "            \"BirdIndividualIDSegmented\",  # License: None\n",
    "            \"Giraffes\",  # License: None\n",
    "            \"IPanda50\",  # License: None\n",
    "            \"NyalaData\",  # License: None\n",
    "            # check for license problems\n",
    "            # \"HumpbackWhaleID\" # not in paper, fine license\n",
    "            # \"HappyWhale\" # not in paper, fine license\n",
    "            # \"LionData\" # not in paper, not found online? (license?)\n",
    "            # \"MacaqueFaces\" # not in paper, fine license -> CC BY 4.0\n",
    "            \"NOAARightWhale\",  # not in paper, license raises questions\n",
    "        }:\n",
    "            continue\n",
    "        d = loader.load_dataset(\n",
    "            ds_cls,\n",
    "            \"/workspaces/gorillatracker/data/WildlifeReID-10k/data\",\n",
    "            \"/workspaces/gorillatracker/data/WildlifeReID-10k/dataframes\",\n",
    "        )\n",
    "        columns = [\"identity\", \"path\", \"bbox\"] if \"bbox\" in d.df.columns else [\"identity\", \"path\"]\n",
    "        df = d.df.loc[:, columns]\n",
    "        df.drop(df[df[\"identity\"] == d.unknown_name].index, inplace=True)\n",
    "        to_drop = df[\"identity\"].value_counts()[df[\"identity\"].value_counts() < 2].index\n",
    "        df.drop(df[df[\"identity\"].isin(to_drop)].index, inplace=True)\n",
    "        df[\"origin\"] = name\n",
    "        df[\"identity\"] = df[\"identity\"].apply(lambda x: f\"{name}_{x}\")\n",
    "        df[\"path\"] = name + \"/\" + df[\"path\"]\n",
    "        df[\"label\"] = LabelEncoder().encode_list(df[\"identity\"].values.tolist())\n",
    "\n",
    "        dfs.append(df)\n",
    "    combined_df = pd.concat(dfs)\n",
    "    combined_df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "    # perform train-val-test split\n",
    "    train_individuals = []\n",
    "    val_individuals = []\n",
    "    test_individuals = []\n",
    "    for name in combined_df[\"origin\"].unique():\n",
    "        df = combined_df[combined_df[\"origin\"] == name]\n",
    "        individuals = df[\"label\"].unique().tolist()\n",
    "        rng.shuffle(individuals)\n",
    "\n",
    "        # split into train-val-test\n",
    "        train_individuals += individuals[: int(train_factor * len(individuals))]\n",
    "        val_individuals += individuals[\n",
    "            int(train_factor * len(individuals)) : int((train_factor + val_factor) * len(individuals))\n",
    "        ]\n",
    "        test_individuals += individuals[int((train_factor + val_factor) * len(individuals)) :]\n",
    "\n",
    "    combined_df[\"split\"] = \"train\"\n",
    "    combined_df.loc[combined_df[\"label\"].isin(val_individuals), \"split\"] = \"val\"\n",
    "    combined_df.loc[combined_df[\"label\"].isin(test_individuals), \"split\"] = \"test\"\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "class MultiSpeciesContrastiveSampler(ContrastiveSampler):\n",
    "    def __init__(\n",
    "        self, base_dir: Path, partition: Literal[\"train\", \"val\", \"test\"] = \"train\", use_primates: bool = True\n",
    "    ) -> None:\n",
    "        self.base_dir = base_dir\n",
    "        self.ds = get_ds_dfs(use_primates=use_primates)\n",
    "        self.ds = self.ds[self.ds[\"split\"] == partition] if partition in {\"train\", \"val\", \"test\"} else self.ds\n",
    "        self.ds.reset_index(drop=False, inplace=True)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> ContrastiveImage:\n",
    "        img = ContrastiveImage(\n",
    "            id=str(idx),\n",
    "            image_path=self.base_dir / self.ds.iloc[idx][\"path\"],\n",
    "            class_label=self.ds.iloc[idx][\"label\"],\n",
    "        )\n",
    "        return img\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.ds)\n",
    "\n",
    "    @property\n",
    "    def class_labels(self) -> list[gtypes.Label]:\n",
    "        return self.ds[\"label\"].unique().tolist()\n",
    "\n",
    "    def positive(\n",
    "        self, sample: ContrastiveImage\n",
    "    ) -> ContrastiveImage:  # must map whatever __getitem__ returns to another sample\n",
    "        positive_class = sample.class_label\n",
    "        if len(self.ds[self.ds[\"label\"] == positive_class]) == 1:\n",
    "            # logger.warning(f\"Only one sample in class {positive_class}. Returning same sample as positive.\")\n",
    "            return sample\n",
    "        positive_indices = self.ds[self.ds[\"label\"] == positive_class].index\n",
    "        positive_indices = positive_indices[positive_indices != sample.id]\n",
    "        positive_index = random.choice(positive_indices)\n",
    "        sample_row = self.ds.iloc[positive_index]\n",
    "\n",
    "        sample = ContrastiveImage(\n",
    "            id=str(positive_index),\n",
    "            image_path=self.base_dir / sample_row[\"path\"],\n",
    "            class_label=sample_row[\"label\"],\n",
    "        )\n",
    "        return sample\n",
    "\n",
    "    # NOTE(memben): First samples a negative class to ensure a more balanced distribution of negatives,\n",
    "    # independent of the number of samples per class\n",
    "    def negative(self, sample: ContrastiveImage) -> ContrastiveImage:\n",
    "        \"\"\"Different class is sampled uniformly at random and a random sample from that class is returned\"\"\"\n",
    "        # filter for the same origin -> species\n",
    "        sample_origin = self.ds.iloc[int(sample.id)][\"origin\"]\n",
    "        same_ds = self.ds[self.ds[\"origin\"] == sample_origin]\n",
    "        same_ds = same_ds[same_ds[\"label\"] != sample.class_label]\n",
    "        negative_class = random.choice(same_ds[\"label\"].unique())\n",
    "        negative_indices = same_ds[same_ds[\"label\"] == negative_class].index\n",
    "        negative_index = random.choice(negative_indices)\n",
    "        sample_row = self.ds.iloc[negative_index]\n",
    "\n",
    "        sample = ContrastiveImage(\n",
    "            id=str(negative_index),\n",
    "            image_path=self.base_dir / sample_row[\"path\"],\n",
    "            class_label=sample_row[\"label\"],\n",
    "        )\n",
    "        return sample\n",
    "\n",
    "    def negative_classes(self, img: ContrastiveImage) -> list[Label]:\n",
    "        class_label = img.class_label\n",
    "        return [label for label in self.contrastive_sampler.class_labels if label != class_label]  # type: ignore\n",
    "\n",
    "\n",
    "class MultiSpeciesSupervisedDataset(NletDataset):\n",
    "    \"\"\"\n",
    "    A dataset that assumes the following directory structure:\n",
    "        base_dir/\n",
    "            train/\n",
    "                ...\n",
    "            val/\n",
    "                ...\n",
    "            test/\n",
    "                ...\n",
    "    Each file is prefixed with the class label, e.g. \"label1_1.jpg\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, use_gorillas: bool = True, use_lfw: bool = True, use_primates: bool = True, *args: Any, **kwargs: Any\n",
    "    ) -> None:\n",
    "        self.use_primates = use_primates\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if use_gorillas:\n",
    "            path = (\n",
    "                (\n",
    "                    Path(\"/workspaces/gorillatracker/data/supervised/splits/cxl_faces_openset_seed_42_square/\")\n",
    "                    / self.partition\n",
    "                )\n",
    "                if self.partition in {\"train\", \"val\", \"test\"}\n",
    "                else Path(\"/workspaces/gorillatracker/data/supervised/cxl_all/face_images\")\n",
    "            )\n",
    "\n",
    "            classes = group_images_by_label(path)\n",
    "            # convert into dataframe with: path, label, origin, split, identity\n",
    "            labels = []\n",
    "            identities = []\n",
    "            paths = []\n",
    "            for _, contrastive_imgs in classes.items():\n",
    "                paths += [img.image_path for img in contrastive_imgs]\n",
    "                labels += [img.class_label for img in contrastive_imgs]\n",
    "                identities += [img.id for img in contrastive_imgs]\n",
    "\n",
    "            gorilla_df = pd.DataFrame(\n",
    "                {\n",
    "                    \"path\": paths,\n",
    "                    \"label\": labels,\n",
    "                    \"identity\": identities,\n",
    "                    \"origin\": \"gorillas\",\n",
    "                    \"split\": self.partition,\n",
    "                    \"bbox\": None,\n",
    "                }\n",
    "            )\n",
    "            gorilla_df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "            self.contrastive_sampler.ds = pd.concat([self.contrastive_sampler.ds, gorilla_df])  # type: ignore\n",
    "            self.contrastive_sampler.ds = self.contrastive_sampler.ds.reset_index(drop=True)  # type: ignore\n",
    "\n",
    "        if use_lfw:\n",
    "            lfw_people = fetch_lfw_people(resize=1.0, color=True)\n",
    "            self.lfw_images = lfw_people.images\n",
    "            self.lfw_targets = lfw_people.target\n",
    "            self.lfw_target_names = lfw_people.target_names\n",
    "            self.lfw_topil = transforms.ToPILImage()\n",
    "\n",
    "            # perform train-val-test split\n",
    "            individuals = np.unique(self.lfw_targets)\n",
    "\n",
    "            # only keep individuals with >=3 images\n",
    "            individuals = [ind for ind in individuals if np.sum(self.lfw_targets == ind) >= 3]\n",
    "\n",
    "            rng = random.Random(42)\n",
    "            rng.shuffle(individuals)\n",
    "\n",
    "            # filter for 'partition' individuals\n",
    "            if self.partition == \"train\":\n",
    "                individuals = individuals[: int(0.7 * len(individuals))]\n",
    "            elif self.partition == \"val\":\n",
    "                individuals = individuals[int(0.7 * len(individuals)) : int(0.85 * len(individuals))]\n",
    "            elif self.partition == \"test\":\n",
    "                individuals = individuals[int(0.85 * len(individuals)) :]\n",
    "\n",
    "            indices = [idx for idx, target in enumerate(self.lfw_targets) if target in individuals]\n",
    "            self.lfw_images = self.lfw_images[indices]\n",
    "            self.lfw_targets = self.lfw_targets[indices]\n",
    "            self.lfw_target_names = self.lfw_target_names[self.lfw_targets]\n",
    "\n",
    "            os.makedirs(f\"/workspaces/gorillatracker/data/LabeledFacesInTheWild/{self.partition}\", exist_ok=True)\n",
    "\n",
    "            for idx, img in enumerate(self.lfw_images):\n",
    "                pil_img = self.lfw_topil(img)\n",
    "                (\n",
    "                    pil_img.save(f\"/workspaces/gorillatracker/data/LabeledFacesInTheWild/{self.partition}/{idx}.jpg\")\n",
    "                    if not Path(\n",
    "                        f\"/workspaces/gorillatracker/data/LabeledFacesInTheWild/{self.partition}/{idx}.jpg\"\n",
    "                    ).exists()\n",
    "                    else None\n",
    "                )\n",
    "\n",
    "            lfw_df = pd.DataFrame(\n",
    "                {\n",
    "                    \"path\": [\n",
    "                        f\"/workspaces/gorillatracker/data/LabeledFacesInTheWild/{self.partition}/{idx}.jpg\"\n",
    "                        for idx in range(len(self.lfw_images))\n",
    "                    ],\n",
    "                    \"label\": self.lfw_targets,\n",
    "                    \"identity\": self.lfw_target_names,\n",
    "                    \"origin\": \"LFW\",\n",
    "                    \"split\": self.partition,\n",
    "                    \"bbox\": None,\n",
    "                }\n",
    "            )\n",
    "            lfw_df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "            self.contrastive_sampler.ds = pd.concat([self.contrastive_sampler.ds, lfw_df])  # type: ignore\n",
    "\n",
    "            self.contrastive_sampler.ds = self.contrastive_sampler.ds.reset_index(drop=True)  # type: ignore\n",
    "            # TODO: add dataset versions for separate metric eval.\n",
    "\n",
    "    def _get_item(self, idx: Label) -> tuple[tuple[Id, ...], tuple[Tensor, ...], tuple[Label, ...]]:\n",
    "        return super()._get_item(idx)\n",
    "\n",
    "    @property\n",
    "    def num_classes(self) -> int:\n",
    "        return len(self.contrastive_sampler)\n",
    "\n",
    "    @property\n",
    "    def class_distribution(self) -> dict[Label, int]:\n",
    "        return self.contrastive_sampler.ds[\"label\"].value_counts().to_dict()  # type: ignore\n",
    "\n",
    "    def create_contrastive_sampler(self, base_dir: Path) -> MultiSpeciesContrastiveSampler:\n",
    "        \"\"\"\n",
    "        Assumes directory structure:\n",
    "            base_dir/\n",
    "                train/\n",
    "                    ...\n",
    "                val/\n",
    "                    ...\n",
    "                test/\n",
    "                    ...\n",
    "        \"\"\"\n",
    "        return MultiSpeciesContrastiveSampler(base_dir, partition=self.partition, use_primates=self.use_primates)\n",
    "\n",
    "    def _stack_flat_nlet(self, flat_nlet: FlatNlet) -> Nlet:\n",
    "        ids = tuple(str(img.image_path) for img in flat_nlet)\n",
    "        labels = tuple(img.class_label for img in flat_nlet)\n",
    "\n",
    "        values = tuple(self.transform(self._crop_if_necessary(img)) for img in flat_nlet)\n",
    "        return ids, values, labels\n",
    "\n",
    "    def _crop_if_necessary(self, img: ContrastiveImage) -> Image.Image:\n",
    "        pilimg = Image.open(img.image_path)\n",
    "        if \"bbox\" in self.contrastive_sampler.ds.columns and isinstance(  # type: ignore\n",
    "            self.contrastive_sampler.ds.iloc[int(img.id)][\"bbox\"], list  # type: ignore\n",
    "        ):\n",
    "            bbox = self.contrastive_sampler.ds.iloc[int(img.id)][\"bbox\"]  # type: ignore\n",
    "            x, y, w, h = bbox\n",
    "            bbox = (x, y, x + w, y + h)\n",
    "            pilimg = pilimg.crop(bbox)  # type: ignore\n",
    "\n",
    "        pilimg = pilimg.convert(\"RGB\")  # type: ignore\n",
    "\n",
    "        if pilimg.width > 300 and pilimg.height > 300:\n",
    "            ratio = pilimg.width / pilimg.height\n",
    "            if ratio > 1:\n",
    "                pilimg = pilimg.resize((300, int(300 / ratio)))  # type: ignore\n",
    "            else:\n",
    "                pilimg = pilimg.resize((int(300 * ratio), 300))  # type: ignore\n",
    "        return pilimg\n",
    "\n",
    "    def __len__(self) -> Label:\n",
    "        return len(self.contrastive_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GorillasPrimatesSupervisedDataset(MultiSpeciesSupervisedDataset):\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(use_gorillas=True, use_lfw=False, use_primates=True, *args, **kwargs)\n",
    "\n",
    "\n",
    "class GorillasPrimatesLFWSupervisedDataset(MultiSpeciesSupervisedDataset):\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(use_gorillas=True, use_lfw=True, use_primates=True, *args, **kwargs)\n",
    "\n",
    "\n",
    "class PrimatesLFWSupervisedDataset(MultiSpeciesSupervisedDataset):\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(use_gorillas=False, use_lfw=True, use_primates=True, *args, **kwargs)\n",
    "\n",
    "\n",
    "class MultispeciesLFW(MultiSpeciesSupervisedDataset):\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(use_gorillas=False, use_lfw=True, use_primates=False, *args, **kwargs)\n",
    "\n",
    "\n",
    "class LFW_only(MultiSpeciesSupervisedDataset):  # TODO\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(use_gorillas=True, use_lfw=True, use_primates=False, *args, **kwargs)\n",
    "        self.contrastive_sampler.ds = self.contrastive_sampler.ds[self.contrastive_sampler.ds[\"origin\"] == \"lfw\"].copy()\n",
    "\n",
    "\n",
    "class Macaques_only(MultiSpeciesSupervisedDataset):  # TODO\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(use_gorillas=False, use_lfw=False, use_primates=True, *args, **kwargs)\n",
    "\n",
    "        self.contrastive_sampler.ds = self.contrastive_sampler.ds[\n",
    "            self.contrastive_sampler.ds[\"origin\"] == \"MacaqueFaces\"\n",
    "        ].copy()\n",
    "\n",
    "\n",
    "class Chimpanzee_only(MultiSpeciesSupervisedDataset):  # TODO\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(use_gorillas=False, use_lfw=False, use_primates=True, *args, **kwargs)\n",
    "\n",
    "        self.contrastive_sampler.ds = self.contrastive_sampler.ds[\n",
    "            (self.contrastive_sampler.ds[\"origin\"] == \"CTai\") | (self.contrastive_sampler.ds[\"origin\"] == \"CZoo\")\n",
    "        ].copy()\n",
    "\n",
    "        self.contrastive_sampler.ds.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "class AllCombined(MultiSpeciesSupervisedDataset):\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(use_gorillas=True, use_lfw=True, use_primates=True, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandAugment\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = lambda x: x\n",
    "\n",
    "dataset = AllCombined(\n",
    "    # use_gorillas=True,\n",
    "    partition=\"all\",\n",
    "    base_dir=Path(\"/workspaces/gorillatracker/data/WildlifeReID-10k/data\"),\n",
    "    transform=transform,\n",
    "    nlet_builder=build_onelet,\n",
    "    aug_num_ops=4,\n",
    "    aug_magnitude=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.contrastive_sampler.ds\n",
    "print(len(df.loc[df[\"origin\"] == \"gorillas\"]))\n",
    "print(len(df.loc[df[\"origin\"] == \"lfw\"]))\n",
    "print(len(df.loc[df[\"origin\"] == \"MacaqueFaces\"]))\n",
    "print(len(df.loc[df[\"origin\"] == \"CTai\"]))\n",
    "print(len(df.loc[df[\"origin\"] == \"CZoo\"]))\n",
    "print(len(df))\n",
    "\n",
    "sample = dataset[20000]\n",
    "img = transforms.ToPILImage()(sample[1][0])\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make table\n",
    "def dict_to_latex_table(data):\n",
    "    # Begin the LaTeX table\n",
    "    latex_str = \"\\\\begin{tabular}{|c|c|c|}\\n\"\n",
    "    latex_str += \"\\\\hline\\n\"\n",
    "    latex_str += \"Column 1 & Column 2 & Column 3 \\\\\\\\\\n\"\n",
    "    latex_str += \"\\\\hline\\n\"\n",
    "\n",
    "    # Add the data\n",
    "    for key, value in data.items():\n",
    "        if len(value) == 2:\n",
    "            latex_str += f\"{key} & {value[0]} & {value[1]} \\\\\\\\\\n\"\n",
    "            latex_str += \"\\\\hline\\n\"\n",
    "\n",
    "    # End the LaTeX table\n",
    "    latex_str += \"\\\\end{tabular}\"\n",
    "\n",
    "    return latex_str\n",
    "\n",
    "\n",
    "datasets = df[\"origin\"].unique()\n",
    "data = {}\n",
    "for dataset in datasets:\n",
    "    data[dataset] = [len(df[df[\"origin\"] == dataset][\"label\"].unique()), len(df[df[\"origin\"] == dataset])]\n",
    "\n",
    "print(dict_to_latex_table(data))\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... per Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"origin\"].nunique())\n",
    "print(df[\"label\"].nunique())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir = \"/workspaces/gorillatracker/data/WildlifeReID-10k/data\"\n",
    "\n",
    "img_sizes = []\n",
    "# df = df[df[\"origin\"] == \"MacaqueFaces\"].copy()\n",
    "\n",
    "for row in df.itertuples():\n",
    "    if row.origin != \"SPACGorillas2023\":\n",
    "        path = os.path.join(base_dir, row.path)\n",
    "    else:\n",
    "        path = row.path\n",
    "\n",
    "    img = Image.open(path)\n",
    "    img_sizes.append(img.size)\n",
    "\n",
    "len(img_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a matrix histogram of the image sizes (width x height)\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "amounts_x, amounts_y = [x[0] for x in img_sizes], [x[1] for x in img_sizes]\n",
    "norm = LogNorm(vmax=20000)\n",
    "plt.hist2d(amounts_x, amounts_y, bins=range(0, 2100, 100), cmap=\"Greens\", norm=norm)\n",
    "for i in range(0, 2000, 100):\n",
    "    for j in range(0, 2000, 100):\n",
    "        plt.text(\n",
    "            i + 50,\n",
    "            j + 50,\n",
    "            f\"{len([1 for x in img_sizes if i <= x[0] < i+100 and j <= x[1] < j+100])}\",\n",
    "            color=\"black\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "plt.xlabel(\"Width\")\n",
    "plt.ylabel(\"Height\")\n",
    "plt.xticks(range(0, 2100, 100))\n",
    "plt.yticks(range(0, 2100, 100))\n",
    "plt.title(\"Image Sizes\")\n",
    "# plt.colorbar()\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\")\n",
    "# plt.savefig(\"plots/spac/bodies_image_sizes.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_low_res = [x for x in img_sizes if x[0] < 200 and x[1] < 200][0]\n",
    "low_res = [x for x in img_sizes if 200 <= x[0] < 400 and 200 <= x[1] < 400][0]\n",
    "mid_res = [x for x in img_sizes if 400 <= x[0] < 700 and 400 <= x[1] < 700][0]\n",
    "high_res = [x for x in img_sizes if x[0] > 800 and x[1] > 800][1]\n",
    "\n",
    "\n",
    "def get_img(index):\n",
    "    if df.iloc[index][\"origin\"] != \"SPACGorillas2023\":\n",
    "        return Image.open(os.path.join(base_dir, df.iloc[index][\"path\"]))\n",
    "    else:\n",
    "        return Image.open(df.iloc[index][\"path\"])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 4, 1)\n",
    "img = get_img(img_sizes.index(very_low_res))\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Very Low Resolution: {very_low_res[0]}x{very_low_res[1]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 2)\n",
    "img = get_img(img_sizes.index(low_res))\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Low Resolution: {low_res[0]}x{low_res[1]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 3)\n",
    "img = get_img(img_sizes.index(mid_res))\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Mid Resolution: {mid_res[0]}x{mid_res[1]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 4)\n",
    "img = get_img(img_sizes.index(high_res))\n",
    "plt.imshow(img)\n",
    "plt.title(f\"High Resolution: {high_res[0]}x{high_res[1]}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# plt.savefig(\"plots/spac/body_resolution_samples.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 4 random dataset faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macaque_faces = df[df[\"origin\"] == \"MacaqueFaces\"].sample(4)\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "counter = 0\n",
    "for i, row in macaque_faces.iterrows():\n",
    "    plt.subplot(1, 4, counter + 1)\n",
    "    img = get_img(i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(row[\"identity\"])\n",
    "    plt.axis(\"off\")\n",
    "    counter += 1\n",
    "\n",
    "plt.savefig(\"plots/primate/macaque_faces_samples.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "czoo_faces = df[df[\"origin\"] == \"CZoo\"].sample(4)\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "counter = 0\n",
    "for i, row in czoo_faces.iterrows():\n",
    "    plt.subplot(1, 4, counter + 1)\n",
    "    img = get_img(i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(row[\"identity\"])\n",
    "    plt.axis(\"off\")\n",
    "    counter += 1\n",
    "\n",
    "plt.savefig(\"plots/primate/czoo_faces_samples.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctai_faces = df[df[\"origin\"] == \"CTai\"].sample(4)\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "counter = 0\n",
    "for i, row in ctai_faces.iterrows():\n",
    "    plt.subplot(1, 4, counter + 1)\n",
    "    img = get_img(i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(row[\"identity\"])\n",
    "    plt.axis(\"off\")\n",
    "    counter += 1\n",
    "\n",
    "plt.savefig(\"plots/primate/ctai_faces_samples.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some stats for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin = \"MacaqueFaces\"\n",
    "\n",
    "# df_stats = df[df[\"origin\"] == origin].copy()\n",
    "\n",
    "num_images = len(df)\n",
    "num_individuals = df[\"label\"].nunique()\n",
    "print(f\"Number of images: {num_images}\")\n",
    "print(f\"Number of individuals: {num_individuals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General statistics\n",
    "### ... per Dataset\n",
    "from matplotlib.ticker import LogLocator, LogFormatterSciNotation\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 500\n",
    "ax = df.groupby(\"origin\")[\"label\"].nunique().plot(kind=\"bar\")\n",
    "ax.patches[0].set_facecolor(\"peachpuff\")\n",
    "ax.patches[1].set_facecolor(\"orange\")\n",
    "ax.patches[2].set_facecolor(\"tomato\")\n",
    "ax.patches[3].set_facecolor(\"firebrick\")\n",
    "ax.patches[4].set_facecolor(\"lightcoral\")\n",
    "ax.set_yscale(\"log\", base=10)\n",
    "\n",
    "for i in range(5):\n",
    "    ax.patches[i].set_edgecolor(\"black\")\n",
    "    ax.patches[i].set_linewidth(0.5)\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.xaxis.set_tick_params(rotation=0)\n",
    "ax.set_ylabel(\"Number of Individuals\")\n",
    "\n",
    "# add exact numbers\n",
    "for i, v in enumerate(df.groupby(\"origin\")[\"label\"].nunique()):\n",
    "    ax.text(i, v + 0.7, str(v), ha=\"center\")\n",
    "\n",
    "plt.savefig(\"plots/primate/individuals_per_species.pdf\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ax = df.groupby(\"origin\")[\"label\"].count().plot(kind=\"bar\")\n",
    "ax.patches[0].set_facecolor(\"peachpuff\")\n",
    "ax.patches[1].set_facecolor(\"orange\")\n",
    "ax.patches[2].set_facecolor(\"tomato\")\n",
    "ax.patches[3].set_facecolor(\"firebrick\")\n",
    "ax.patches[4].set_facecolor(\"lightcoral\")\n",
    "\n",
    "# add borders\n",
    "for i in range(5):\n",
    "    ax.patches[i].set_edgecolor(\"black\")\n",
    "    ax.patches[i].set_linewidth(0.5)\n",
    "\n",
    "for i, v in enumerate(df.groupby(\"origin\")[\"label\"].count()):\n",
    "    ax.text(i, v + 50, str(v), ha=\"center\")\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.xaxis.set_tick_params(rotation=0)\n",
    "ax.set_ylabel(\"Number of Samples\")\n",
    "\n",
    "plt.savefig(\"plots/primate/individuals_samples_per_species.pdf\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# combine into boxplot of number of samples per individual / label per origin / species\n",
    "# df.groupby([\"origin\", \"label\"]).count().reset_index().boxplot(column=\"\", by=\"origin\")\n",
    "df_with_counts = df.groupby([\"origin\", \"label\"]).count().reset_index()\n",
    "# axis = df_with_counts.boxplot(column=\"index\", by=\"origin\")\n",
    "\n",
    "fig, axis = plt.subplots()\n",
    "fig.dpi = 500\n",
    "# df_with_counts.boxplot(column=\"index\", by=\"origin\", ax=axis, showfliers=False, rot=90, figsize=(20, 5), grid=True)\n",
    "# parse the boxplot manually\n",
    "\n",
    "plot_colors = [\"peachpuff\", \"orange\", \"tomato\", \"firebrick\", \"lightcoral\"]\n",
    "for i, name in enumerate(df_with_counts[\"origin\"].unique()):\n",
    "\n",
    "    bplot = axis.boxplot(\n",
    "        [df_with_counts[df_with_counts[\"origin\"] == name][\"index\"].to_list()],\n",
    "        positions=[i],\n",
    "        patch_artist=True,\n",
    "        tick_labels=[name],\n",
    "        widths=0.6,\n",
    "    )\n",
    "\n",
    "    patch = bplot[\"boxes\"][0]\n",
    "    patch.set_facecolor(plot_colors[i])\n",
    "\n",
    "\n",
    "# axis.set_title(\"Number of samples per individual / label per origin / species\")\n",
    "axis.set_ylabel(\"Number of samples per individual\")\n",
    "\n",
    "\n",
    "axis.set_yscale(\"log\", base=2)\n",
    "axis.set_ylim(1, 1024)\n",
    "axis.set_yticks([10**i for i in range(3)], labels=[10**i for i in range(3)])\n",
    "axis.yaxis.set_minor_locator(LogLocator(base=10, subs=\"auto\", numticks=10))\n",
    "axis.yaxis.set_minor_formatter(LogFormatterSciNotation())\n",
    "\n",
    "axis.grid(axis=\"y\", which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "fig.savefig(\"plots/primate/individual_samples_per_species.pdf\")\n",
    "plt.show()\n",
    "\n",
    "### Do quality analysis of Macaque Face Dataset\n",
    "import os\n",
    "\n",
    "base_dir = \"/workspaces/gorillatracker/data/WildlifeReID-10k/data\"\n",
    "\n",
    "img_sizes = []\n",
    "# df = df[df[\"origin\"] == \"MacaqueFaces\"].copy()\n",
    "\n",
    "for row in df.itertuples():\n",
    "    if row.origin != \"SPACGorillas2023\":\n",
    "        path = os.path.join(base_dir, row.path)\n",
    "    else:\n",
    "        path = row.path\n",
    "\n",
    "    img = Image.open(path)\n",
    "    img_sizes.append(img.size)\n",
    "\n",
    "len(img_sizes)\n",
    "# make a matrix histogram of the image sizes (width x height)\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "amounts_x, amounts_y = [x[0] for x in img_sizes], [x[1] for x in img_sizes]\n",
    "norm = LogNorm(vmax=10000)\n",
    "plt.hist2d(amounts_x, amounts_y, bins=range(0, 1100, 100), cmap=\"Greens\", norm=norm)\n",
    "for i in range(0, 1000, 100):\n",
    "    for j in range(0, 1000, 100):\n",
    "        plt.text(\n",
    "            i + 50,\n",
    "            j + 50,\n",
    "            f\"{len([1 for x in img_sizes if i <= x[0] < i+100 and j <= x[1] < j+100])}\",\n",
    "            color=\"black\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "plt.xlabel(\"Width\")\n",
    "plt.ylabel(\"Height\")\n",
    "plt.xticks(range(0, 1100, 100))\n",
    "plt.yticks(range(0, 1100, 100))\n",
    "plt.title(\"Image Sizes\")\n",
    "# plt.colorbar()\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\")\n",
    "# plt.savefig(\"plots/spac/bodies_image_sizes.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "very_low_res = [x for x in img_sizes if x[0] < 200 and x[1] < 200][0]\n",
    "low_res = [x for x in img_sizes if 200 <= x[0] < 400 and 200 <= x[1] < 400][0]\n",
    "mid_res = [x for x in img_sizes if 400 <= x[0] < 700 and 400 <= x[1] < 700][0]\n",
    "high_res = [x for x in img_sizes if x[0] > 800 and x[1] > 800][1]\n",
    "\n",
    "\n",
    "def get_img(index):\n",
    "    if df.iloc[index][\"origin\"] != \"SPACGorillas2023\":\n",
    "        return Image.open(os.path.join(base_dir, df.iloc[index][\"path\"]))\n",
    "    else:\n",
    "        return Image.open(df.iloc[index][\"path\"])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 4, 1)\n",
    "img = get_img(img_sizes.index(very_low_res))\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Very Low Resolution: {very_low_res[0]}x{very_low_res[1]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 2)\n",
    "img = get_img(img_sizes.index(low_res))\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Low Resolution: {low_res[0]}x{low_res[1]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 3)\n",
    "img = get_img(img_sizes.index(mid_res))\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Mid Resolution: {mid_res[0]}x{mid_res[1]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 4)\n",
    "img = get_img(img_sizes.index(high_res))\n",
    "plt.imshow(img)\n",
    "plt.title(f\"High Resolution: {high_res[0]}x{high_res[1]}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# plt.savefig(\"plots/spac/body_resolution_samples.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "### Get 4 random dataset faces\n",
    "macaque_faces = df[df[\"origin\"] == \"MacaqueFaces\"].sample(4)\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "counter = 0\n",
    "for i, row in macaque_faces.iterrows():\n",
    "    plt.subplot(1, 4, counter + 1)\n",
    "    img = get_img(i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(row[\"identity\"])\n",
    "    plt.axis(\"off\")\n",
    "    counter += 1\n",
    "\n",
    "plt.savefig(\"plots/primate/macaque_faces_samples.pdf\", bbox_inches=\"tight\")\n",
    "czoo_faces = df[df[\"origin\"] == \"CZoo\"].sample(4)\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "counter = 0\n",
    "for i, row in czoo_faces.iterrows():\n",
    "    plt.subplot(1, 4, counter + 1)\n",
    "    img = get_img(i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(row[\"identity\"])\n",
    "    plt.axis(\"off\")\n",
    "    counter += 1\n",
    "\n",
    "plt.savefig(\"plots/primate/czoo_faces_samples.pdf\", bbox_inches=\"tight\")\n",
    "ctai_faces = df[df[\"origin\"] == \"CTai\"].sample(4)\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "counter = 0\n",
    "for i, row in ctai_faces.iterrows():\n",
    "    plt.subplot(1, 4, counter + 1)\n",
    "    img = get_img(i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(row[\"identity\"])\n",
    "    plt.axis(\"off\")\n",
    "    counter += 1\n",
    "\n",
    "plt.savefig(\"plots/primate/ctai_faces_samples.pdf\", bbox_inches=\"tight\")\n",
    "### Show some stats for all datasets\n",
    "# origin = \"MacaqueFaces\"\n",
    "\n",
    "# df_stats = df[df[\"origin\"] == origin].copy()\n",
    "\n",
    "num_images = len(df)\n",
    "num_individuals = df[\"label\"].nunique()\n",
    "print(f\"Number of images: {num_images}\")\n",
    "print(f\"Number of individuals: {num_individuals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
