{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gorillatracker.miewid_model import MiewIdNet\n",
    "\n",
    "bin_path = \"/workspaces/gorillatracker/models/miew_id.ms_face.bin\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_params = {  # TODO\n",
    "    \"n_classes\": 1977,  # some value\n",
    "    \"model_name\": \"timm/efficientnetv2_rw_m\",\n",
    "    \"use_fc\": False,\n",
    "    \"fc_dim\": 2152,\n",
    "    \"dropout\": 0.0,\n",
    "    \"loss_module\": \"softmax\",\n",
    "    \"s\": 49.32675426153405,\n",
    "    \"margin\": 0.32,\n",
    "    \"ls_eps\": 0.0,\n",
    "    \"theta_zero\": 0.785,\n",
    "    \"pretrained\": True,\n",
    "    \"margins\": None,\n",
    "    \"k\": None,\n",
    "}\n",
    "\n",
    "if bin_path:\n",
    "    weights = torch.load(bin_path, map_location=torch.device(device))\n",
    "    weights.pop(\"final.wmetric_classify.weight\")  # irrelevant for inference\n",
    "    weights.pop(\"final.warcface_margin.margins\")  # irrelevant for inference\n",
    "\n",
    "    model = MiewIdNet(**dict(model_params))\n",
    "    model.to(device)\n",
    "    model.final = torch.nn.Identity()\n",
    "    print(model.load_state_dict(weights, strict=False))\n",
    "    # model.final = torch.nn.Identity()\n",
    "    model.eval()\n",
    "    print(\"loaded checkpoint from \", bin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.randn(1, 3, 224, 224).to(device)\n",
    "output = model(test)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gorillatracker.utils.embedding_generator import generate_embeddings\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from gorillatracker.transform_utils import SquarePad\n",
    "from gorillatracker.datasets.cxl import CXLDataset\n",
    "\n",
    "\n",
    "model_transforms = transforms.Compose(\n",
    "    [\n",
    "        SquarePad(),\n",
    "        # Uniform input, you may choose higher/lower sizes.\n",
    "        transforms.Resize(440),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Resize((192), antialias=True),\n",
    "        # transforms_v2.Normalize([0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "dataset = CXLDataset(\n",
    "    data_dir=\"/workspaces/gorillatracker/data/splits/ground_truth-cxl-face_images-openset-reid-val-0-test-0-mintraincount-3-seed-42-train-50-val-25-test-25\",\n",
    "    partition=\"val\",\n",
    "    transform=model_transforms,\n",
    ")\n",
    "\n",
    "df = generate_embeddings(model, dataset, device=\"cpu\", norm_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_latex_table(metrics, formatted_names):\n",
    "    latex_table = r\"\"\"\n",
    "\\begin{table}\n",
    "    \\centering\n",
    "    \\resizebox{0.8\\paperwidth}{!}{\n",
    "    \\begin{tabular}{l *{8}{c}}\n",
    "    \\toprule\n",
    "    & \\multicolumn{2}{c}{Bristol} & \\multicolumn{2}{c}{SPAC} & \\multicolumn{2}{c}{Bristol} & \\multicolumn{2}{c}{SPAC} \\\\\n",
    "    \\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7} \\cmidrule(lr){8-9}\n",
    "    Metric & ViT-F & ViT-P & ViT-F & ViT-P & EfN-F & EfN-P & EfN-F & EfN-P \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "    for metric, formatted_name in formatted_names.items():\n",
    "        row = f\"{formatted_name} \"\n",
    "        for model_prefix in [\"ViT-\", \"EfN-\"]:\n",
    "            for dataset in [\"Bristol\", \"SPAC\"]:\n",
    "                for model_suffix in [\"F\", \"P\"]:\n",
    "                    model = f\"{model_prefix}{model_suffix}\"\n",
    "                    value = metrics.get((model, dataset), {}).get(metric, \"-\")\n",
    "                    if isinstance(value, float):\n",
    "                        row += f\"& {value:.2f} \"\n",
    "                    else:\n",
    "                        row += f\"& {value} \"\n",
    "        row += r\"\\\\\"\n",
    "        latex_table += row + \"\\n\"\n",
    "\n",
    "    latex_table += r\"\"\"    \\bottomrule\n",
    "    \\end{tabular}\n",
    "    }\n",
    "    \\caption{Metrics comparison across models and datasets.}\n",
    "    \\label{tab:metrics-comparison}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    return latex_table\n",
    "\n",
    "\n",
    "df = merged_df\n",
    "actual_metrics = {\n",
    "    (\"ViT-F\", \"SPAC\"): analyse_embedding_space(df[(df[\"model\"] == \"ViT-Finetuned\") & (df[\"dataset\"] == \"SPAC\")]),\n",
    "    (\"ViT-P\", \"SPAC\"): analyse_embedding_space(df[(df[\"model\"] == \"ViT-Pretrained\") & (df[\"dataset\"] == \"SPAC\")]),\n",
    "    # ('EfN-F', 'SPAC'): analyse_embedding_space(df[(df['model'] == 'EfN-Finetuned') & (df['dataset'] == 'SPAC')]),\n",
    "    (\"EfN-P\", \"SPAC\"): analyse_embedding_space(df[(df[\"model\"] == \"EfN-Pretrained\") & (df[\"dataset\"] == \"SPAC\")]),\n",
    "    (\"ViT-F\", \"Bristol\"): analyse_embedding_space(df[(df[\"model\"] == \"ViT-Finetuned\") & (df[\"dataset\"] == \"Bristol\")]),\n",
    "    (\"ViT-P\", \"Bristol\"): analyse_embedding_space(df[(df[\"model\"] == \"ViT-Pretrained\") & (df[\"dataset\"] == \"Bristol\")]),\n",
    "    # ('EfN-F', 'Bristol'): analyse_embedding_space(df[(df['model'] == 'EfN-Finetuned') & (df['dataset'] == 'Bristol')]),\n",
    "    (\"EfN-P\", \"Bristol\"): analyse_embedding_space(df[(df[\"model\"] == \"EfN-Pretrained\") & (df[\"dataset\"] == \"Bristol\")]),\n",
    "}\n",
    "\n",
    "print(create_latex_table(actual_metrics, formatted_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot embeddings\n",
    "embeddings = df[\"embedding\"].to_numpy()\n",
    "embeddings = np.stack(embeddings)\n",
    "\n",
    "images = []\n",
    "for image in df[\"input\"]:\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=\"JPEG\")\n",
    "    image_byte = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    images.append(image_byte)\n",
    "\n",
    "ep = EmbeddingProjector()\n",
    "low_dim_embeddings = ep.reduce_dimensions(embeddings, method=\"tsne\")\n",
    "ep.plot_clusters(\n",
    "    low_dim_embeddings, df[\"label\"], df[\"label_string\"], images, title=\"Embedding Projector\", figsize=(12, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import pairwise_euclidean_distance\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_closest_indices(embeddings: torch.Tensor, k: int) -> torch.Tensor:\n",
    "    distance_matrix = pairwise_euclidean_distance(embeddings)\n",
    "    distance_matrix.fill_diagonal_(float(\"inf\"))\n",
    "    # Find the indices of the closest embeddings for each embedding\n",
    "    closest_indices = []\n",
    "    for i in range(len(embeddings)):\n",
    "        closest_indices_i = torch.argsort(distance_matrix[i])[:k].tolist()\n",
    "        closest_indices.append(closest_indices_i)\n",
    "\n",
    "    return closest_indices\n",
    "\n",
    "\n",
    "def get_missclassified_images(embeddings_table: pd.DataFrame, k: int) -> None:\n",
    "    misclassified_images = []\n",
    "    labels = embeddings_table[\"label\"]\n",
    "    embeddings = embeddings_table[\"embedding\"].to_numpy()\n",
    "    embeddings = torch.stack(embeddings.tolist())\n",
    "    closest_indices = get_closest_indices(torch.tensor(embeddings), k)\n",
    "    counter = 0\n",
    "    for i in range(len(labels)):\n",
    "        true_label = labels[i]\n",
    "        nearest_labels = []\n",
    "        for j in range(k):\n",
    "            nearest_labels.append(labels[closest_indices[i][j]])\n",
    "        predicted_label = max(nearest_labels, key=nearest_labels.count)\n",
    "        if true_label != predicted_label:\n",
    "            misclassified_images.append((i, *closest_indices[i]))\n",
    "            counter += 1\n",
    "\n",
    "    print(f\"Accuracy: {1 - counter / len(labels)}\")\n",
    "\n",
    "    return misclassified_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_missclassified_images(df, 1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
