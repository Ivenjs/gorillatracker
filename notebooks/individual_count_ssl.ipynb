{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE(liamvdv): todo: move to SSLConfig\n",
    "# from gorillatracker.ssl_pipeline.ssl_config import SSLConfig\n",
    "\n",
    "from sqlalchemy import select, text, create_engine\n",
    "from sqlalchemy.orm import Session\n",
    "from gorillatracker.ssl_pipeline.models import TrackingFrameFeature\n",
    "from gorillatracker.ssl_pipeline.dataset import GorillaDatasetKISZ\n",
    "\n",
    "\n",
    "sample = 10\n",
    "query = text(\n",
    "    f\"\"\"WITH ranked_features AS (\n",
    "    SELECT\n",
    "        tracking_id,\n",
    "        tracking_frame_feature_id,\n",
    "        bbox_width,\n",
    "        bbox_height,\n",
    "        frame_nr,\n",
    "        feature_type,\n",
    "        ROW_NUMBER() OVER (PARTITION BY tracking_id ORDER BY RANDOM()) AS rn\n",
    "    FROM tracking_frame_feature\n",
    "    WHERE feature_type = 'face_45'\n",
    "        AND bbox_width >= 184\n",
    "        AND bbox_height >= 184\n",
    "        AND tracking_id IS NOT NULL\n",
    ")\n",
    "SELECT\n",
    "    tracking_frame_feature_id\n",
    "FROM ranked_features\n",
    "WHERE rn <= {sample}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# engine = create_engine(GorillaDatasetKISZ.DB_URI)\n",
    "\n",
    "# # stmt = select(TrackingFrameFeature).where(TrackingFrameFeature.tracking_frame_feature_id.in_(subquery))\n",
    "\n",
    "# with Session(engine) as session:\n",
    "#     result = session.execute(query).scalars().all()\n",
    "#     for row in result:\n",
    "#         print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Literal, Optional, Tuple\n",
    "\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import gorillatracker.type_helper as gtypes\n",
    "from gorillatracker.transform_utils import SquarePad\n",
    "from gorillatracker.type_helper import Id, Label\n",
    "from gorillatracker.utils.labelencoder import LabelEncoder\n",
    "\n",
    "base_path = \"cropped-images/2024-04-18\"\n",
    "\n",
    "\n",
    "def cast_label_to_int(labels: List[str]) -> List[int]:\n",
    "    return LabelEncoder.encode_list(labels)\n",
    "\n",
    "\n",
    "class HackDataset(Dataset[Tuple[Id, Tensor, Label]]):\n",
    "    def get_tffs(self) -> list[TrackingFrameFeature]:\n",
    "        engine = create_engine(GorillaDatasetKISZ.DB_URI)\n",
    "\n",
    "        stmt = select(TrackingFrameFeature).where(TrackingFrameFeature.tracking_frame_feature_id.in_(query))\n",
    "\n",
    "        with Session(engine) as session:\n",
    "            return session.execute(stmt).scalars().all()\n",
    "\n",
    "    def __init__(\n",
    "        self, data_dir: str, partition: Literal[\"train\", \"val\", \"test\"], transform: Optional[gtypes.Transform] = None\n",
    "    ):\n",
    "        self.ttfs = self.get_tffs()\n",
    "        self.transform = transform\n",
    "        self.partition = partition\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.ttfs)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[Id, Tensor, Label]:\n",
    "        \"\"\"tracklets will be labels for now\"\"\"\n",
    "        ttf = self.ttfs[idx]\n",
    "\n",
    "        img = Image.open(ttf.cache_path(base_path))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        assert ttf.tracking_id is not None\n",
    "        return ttf.tracking_frame_feature_id, img, ttf.tracking_id\n",
    "\n",
    "    @classmethod\n",
    "    def get_transforms(cls) -> gtypes.Transform:\n",
    "        return transforms.Compose(\n",
    "            [\n",
    "                SquarePad(),\n",
    "                # Uniform input, you may choose higher/lower sizes.\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gorillatracker.utils.embedding_generator import (\n",
    "    get_run,\n",
    "    get_model_from_run,\n",
    "    generate_embeddings,\n",
    "    read_embeddings_from_disk,\n",
    ")\n",
    "from torchvision import transforms\n",
    "\n",
    "regen = True\n",
    "file = \"example.pkl\"\n",
    "\n",
    "if regen:\n",
    "    run_url = \"https://wandb.ai/gorillas/Embedding-SwinV2Large-CXL-Open/runs/bp5e1rnx/workspace?nw=nwuserliamvdv\"\n",
    "    run = get_run(run_url)\n",
    "    model = get_model_from_run(run)\n",
    "    dataset = HackDataset(\"\", \"val\", transforms.Compose([HackDataset.get_transforms(), model.get_tensor_transforms()]))\n",
    "    df = generate_embeddings(model, dataset, device=\"gpu\")\n",
    "    df[\"partition\"] = \"val\"\n",
    "    df.to_pickle(file)\n",
    "else:\n",
    "    df = read_embeddings_from_disk(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
