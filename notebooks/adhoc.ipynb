{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from gorillatracker.utils.embedding_generator import read_embeddings_from_disk\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Read embeddings from disk\n",
    "df = read_embeddings_from_disk(\"example.pkl\")\n",
    "\n",
    "# print(len(df[\"label\"].unique()))\n",
    "# X = np.vstack(df[\"embedding\"].values)\n",
    "# # Generate synthetic dataset (replace this with your embeddings)\n",
    "# # X, _ = make_blobs(n_samples=75000, centers=4, cluster_std=0.60, random_state=0)\n",
    "\n",
    "# # Standardize features by removing the mean and scaling to unit variance\n",
    "# X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# # Range of epsilon values to try\n",
    "# eps_values = np.linspace(0.1, 1.5, 15)\n",
    "\n",
    "# # Initialize lists to store silhouette scores and Davies-Bouldin indices\n",
    "# silhouette_scores = []\n",
    "# davies_bouldin_indices = []\n",
    "# num_clusters_list = []\n",
    "\n",
    "# for eps in eps_values:\n",
    "#     print(\"EPS\", eps)\n",
    "#     # Initialize DBSCAN\n",
    "#     dbscan = DBSCAN(eps=eps, min_samples=5, n_jobs=-1)\n",
    "\n",
    "#     # Fit the model and predict the cluster for each data point\n",
    "#     cluster_labels = dbscan.fit_predict(X)\n",
    "\n",
    "#     # Filter out noise points (-1) for silhouette score calculation\n",
    "#     if len(set(cluster_labels)) > 1 and -1 in cluster_labels:\n",
    "#         silhouette_avg = silhouette_score(X[cluster_labels != -1], cluster_labels[cluster_labels != -1])\n",
    "#         db_index = davies_bouldin_score(X[cluster_labels != -1], cluster_labels[cluster_labels != -1])\n",
    "#     elif len(set(cluster_labels)) > 1:\n",
    "#         silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "#         db_index = davies_bouldin_score(X, cluster_labels)\n",
    "#     else:\n",
    "#         silhouette_avg = -1\n",
    "#         db_index = float(\"inf\")\n",
    "\n",
    "#     silhouette_scores.append(silhouette_avg)\n",
    "#     davies_bouldin_indices.append(db_index)\n",
    "#     num_clusters_list.append(len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0))\n",
    "\n",
    "# # Plot silhouette scores\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(eps_values, silhouette_scores, marker=\"o\")\n",
    "# plt.title(\"Silhouette Score\")\n",
    "# plt.xlabel(\"Epsilon (eps)\")\n",
    "# plt.ylabel(\"Silhouette Score\")\n",
    "\n",
    "# # Plot Davies-Bouldin indices\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(eps_values, davies_bouldin_indices, marker=\"o\", color=\"red\")\n",
    "# plt.title(\"Davies-Bouldin Index\")\n",
    "# plt.xlabel(\"Epsilon (eps)\")\n",
    "# plt.ylabel(\"Davies-Bouldin Index\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Find the optimal epsilon based on Silhouette Score and Davies-Bouldin Index\n",
    "# optimal_eps_silhouette = eps_values[np.argmax(silhouette_scores)]\n",
    "# optimal_eps_davies_bouldin = eps_values[np.argmin(davies_bouldin_indices)]\n",
    "\n",
    "# print(f\"Optimal epsilon based on Silhouette Score: {optimal_eps_silhouette}\")\n",
    "# print(f\"Optimal epsilon based on Davies-Bouldin Index: {optimal_eps_davies_bouldin}\")\n",
    "\n",
    "# # Print the number of clusters for the optimal epsilons\n",
    "# print(f\"Number of clusters for optimal Silhouette Score: {num_clusters_list[np.argmax(silhouette_scores)]}\")\n",
    "# print(f\"Number of clusters for optimal Davies-Bouldin Index: {num_clusters_list[np.argmin(davies_bouldin_indices)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_embeddings_from_disk(\"example.pkl\")\n",
    "\n",
    "embeddings = np.vstack(df[\"embedding\"].values)\n",
    "labels = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "score = silhouette_score(embeddings, labels)\n",
    "print(\"Silhouette Score:\", score)\n",
    "print(\"Davies Bouldin Score:\", davies_bouldin_score(embeddings, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming `embeddings` is your numpy array of shape (80k, embedding_dim)\n",
    "pca = PCA(n_components=50)  # Reduce to 50 dimensions or a suitable number\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=40, n_iter=1000, random_state=42)\n",
    "tsne_embeddings = tsne.fit_transform(reduced_embeddings)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(tsne_embeddings[:, 0], tsne_embeddings[:, 1], c=labels, cmap=\"tab10\", s=10)\n",
    "plt.title(\"t-SNE Visualization of Embeddings\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
