{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of architectures: 14\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "architecture_result_paths = list(pathlib.Path(\"../results/gorillas\").glob(\"*\"))\n",
    "print(\"Number of architectures:\", len(list(architecture_result_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import statistics\n",
    "\n",
    "tials_that_should_exist = []\n",
    "for architecture_result_path in architecture_result_paths:\n",
    "    tials_that_should_exist.append(architecture_result_path.name)\n",
    "    tials_that_should_exist.append(architecture_result_path.name + \"-QAT\")\n",
    "    tials_that_should_exist.append(architecture_result_path.name + \"-PTQ\")\n",
    "    tials_that_should_exist.append(architecture_result_path.name + \"-QAT&KD\")\n",
    "    \n",
    "\n",
    "dataframe_list = []\n",
    "trials_that_exist = []\n",
    "for architecture_result_path in architecture_result_paths:\n",
    "    trials = list(architecture_result_path.glob(\"*\"))\n",
    "    \n",
    "    for trial in trials:\n",
    "        config_dict = json.loads((trial / \"config.json\").read_text())\n",
    "        metrics_dict = json.loads((trial / \"metrics.json\").read_text())\n",
    "        \n",
    "        name = trial.parent.name\n",
    "        if \"use_quantization_aware_training\" not in config_dict.keys():\n",
    "            continue\n",
    "        \n",
    "        if config_dict[\"use_quantization_aware_training\"][\"0\"]:\n",
    "            name += \"-QAT\"\n",
    "        if config_dict[\"loss_mode\"][\"0\"] == \"distillation/offline/response-based\":\n",
    "            name += \"&KD\"\n",
    "            \n",
    "        if \"aggregated/cxlkfold/val/embeddings/knn/accuracy_max\" not in metrics_dict.keys():\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            important_metrics = [\n",
    "                'val/embeddings/knn/accuracy_max', \"val/embeddings/knn/precision_max\", \"val/embeddings/knn/f1_max\", \"val/embeddings/knn5/accuracy_max\", \"val/embeddings/knn5/precision_max\", \"val/embeddings/knn5/f1_max\", \"val/embeddings/knn5/accuracy_top5_max\",\n",
    "                'val/embeddings/knn_crossvideo/accuracy_max', \"val/embeddings/knn_crossvideo/precision_max\", \"val/embeddings/knn_crossvideo/f1_max\", \"val/embeddings/knn5_crossvideo/accuracy_max\", \"val/embeddings/knn5_crossvideo/precision_max\", \"val/embeddings/knn5_crossvideo/f1_max\", \"val/embeddings/knn5_crossvideo/accuracy_top5_max\",\n",
    "            ]\n",
    "            dataframe_entry = {\"name\": name}\n",
    "            for metric in important_metrics:\n",
    "                values = []\n",
    "                metric_name = metric.replace(\"knn/\",\"knn-1/\").replace('knn_', \"knn-1_\").split(\"/\")[-2].replace(\"knn5\", \"knn-5\")+ \" \" + metric.split(\"/\")[-1].replace(\"_max\", \"\")\n",
    "                for fold in range(5):\n",
    "                    values.append(metrics_dict[f\"cxlkfold/fold-{fold}/\" + metric]['0'])\n",
    "                \n",
    "                    \n",
    "                dataframe_entry[metric_name + \" stdev\"] = statistics.stdev(values)\n",
    "                dataframe_entry[metric_name + \" mean\"] = statistics.mean(values)\n",
    "                dataframe_entry[metric_name + \" min\"] = min(values)\n",
    "                dataframe_entry[metric_name + \" max\"] = max(values)\n",
    "                dataframe_entry[metric_name] = metrics_dict[\"aggregated/cxlkfold/\" + metric][\"0\"]\n",
    "                    \n",
    "            dataframe_list.append(dataframe_entry)\n",
    "            trials_that_exist.append(name)\n",
    "            \n",
    "dataframe = pd.DataFrame(dataframe_list)\n",
    "dataframe.to_csv(\"gorillas.csv\", index=False)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of architectures: 14\n"
     ]
    }
   ],
   "source": [
    "# get data from ptq\n",
    "\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import json\n",
    "import statistics\n",
    "\n",
    "architecture_result_paths = list(pathlib.Path(\"../runs\").glob(\"*\"))\n",
    "print(\"Number of architectures:\", len(list(architecture_result_paths)))\n",
    "\n",
    "for architecture_path in architecture_result_paths:\n",
    "    results = json.loads((architecture_path / \"results.json\").read_text())\n",
    "    \n",
    "    dataframe_entry = {\"name\": architecture_path.name + \"-PTQ\"}\n",
    "    for metric in important_metrics:\n",
    "        metric_name = metric.replace(\"knn/\",\"knn-1/\").replace('knn_', \"knn-1_\").split(\"/\")[-2].replace(\"knn5\", \"knn-5\")+ \" \" + metric.split(\"/\")[-1].replace(\"_max\", \"\")\n",
    "        knn = metric.replace(\"knn/\", \"knn1/\").replace('knn_', \"knn1_\").split(\"/\")[-2]\n",
    "        metric_name_2 = metric.split(\"/\")[-1].replace(\"_max\", \"\")\n",
    "        \n",
    "        values = []\n",
    "        for fold in range(5):\n",
    "            try:\n",
    "                values.append(results[f\"quantized-fold-{fold}\"][knn][metric_name_2] )\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {architecture_path.name} {knn} {metric_name_2}\")\n",
    "                values.append(0)\n",
    "            \n",
    "        dataframe_entry[metric_name + \" stdev\"] = statistics.stdev(values)\n",
    "        dataframe_entry[metric_name + \" mean\"] = statistics.mean(values)\n",
    "        dataframe_entry[metric_name + \" min\"] = min(values)\n",
    "        dataframe_entry[metric_name + \" max\"] = max(values)\n",
    "        dataframe_entry[metric_name] = min(values)\n",
    "        \n",
    "            \n",
    "    dataframe_list.append(dataframe_entry)\n",
    "    trials_that_exist.append(architecture_path.name + \"-PTQ\")\n",
    "    \n",
    "dataframe = pd.DataFrame(dataframe_list)\n",
    "dataframe.to_csv(\"gorillas.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import matplotlib \n",
    "\n",
    "SPINE_COLOR = 'gray'\n",
    "\n",
    "def latexify(fig_width=None, fig_height=None, columns=1):\n",
    "    \"\"\"Set up matplotlib's RC params for LaTeX plotting.\n",
    "    Call this before plotting a figure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fig_width : float, optional, inches\n",
    "    fig_height : float,  optional, inches\n",
    "    columns : {1, 2}\n",
    "    \"\"\"\n",
    "\n",
    "    # code adapted from http://www.scipy.org/Cookbook/Matplotlib/LaTeX_Examples\n",
    "\n",
    "    # Width and max height in inches for IEEE journals taken from\n",
    "    # computer.org/cms/Computer.org/Journal%20templates/transactions_art_guide.pdf\n",
    "\n",
    "    assert(columns in [1,2])\n",
    "\n",
    "    if fig_width is None:\n",
    "        fig_width = 3.39 if columns==1 else 6.9 # width in inches\n",
    "        #fig_width = 12 if columns==1 else 17 # width in inches\n",
    "\n",
    "    if fig_height is None:\n",
    "        golden_mean = (sqrt(5)-1.0)/2.0    # Aesthetic ratio\n",
    "        fig_height = fig_width*golden_mean # height in inches\n",
    "\n",
    "    MAX_HEIGHT_INCHES = 8.0\n",
    "    if fig_height > MAX_HEIGHT_INCHES:\n",
    "        print(\"WARNING: fig_height too large:\" + fig_height + \n",
    "              \"so will reduce to\" + MAX_HEIGHT_INCHES + \"inches.\")\n",
    "        fig_height = MAX_HEIGHT_INCHES\n",
    "\n",
    "    params = {'backend': 'ps',\n",
    "              'text.latex.preamble': '\\\\usepackage{gensymb}',\n",
    "              'axes.labelsize': 8, # fontsize for x and y labels (was 10)\n",
    "              'axes.titlesize': 8,\n",
    "              'lines.linewidth': 0.5,\n",
    "              'axes.linewidth': 0.5,\n",
    "              #'text.fontsize': 8, # was 10\n",
    "              'legend.fontsize': 8, # was 10\n",
    "              'xtick.labelsize': 8,\n",
    "              'ytick.labelsize': 8,\n",
    "              'lines.markersize': 2,\n",
    "              'text.usetex': True,\n",
    "              'figure.figsize': [fig_width,fig_height],\n",
    "              'font.family': 'serif'\n",
    "    }\n",
    "\n",
    "    matplotlib.rcParams.update(params)\n",
    "\n",
    "\n",
    "def format_axes(ax):\n",
    "\n",
    "    for spine in ['top', 'right']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "    for spine in ['left', 'bottom']:\n",
    "        ax.spines[spine].set_color(SPINE_COLOR)\n",
    "        ax.spines[spine].set_linewidth(0.5)\n",
    "\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    for axis in [ax.xaxis, ax.yaxis]:\n",
    "        axis.set_tick_params(direction='out', color=SPINE_COLOR)\n",
    "\n",
    "    return ax\n",
    "\n",
    "latexify()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tails_that_are_missing = set(tials_that_should_exist) - set(trials_that_exist)\n",
    "tails_that_are_missing = sorted(list(tails_that_are_missing))\n",
    "\n",
    "missing_kd = []\n",
    "missing_baseline = []\n",
    "missing_qat = []\n",
    "missing_ptq = []\n",
    "for tail in tails_that_are_missing:\n",
    "    if \"&KD\" in tail:\n",
    "        missing_kd.append(tail)\n",
    "    elif \"-QAT\" in tail:\n",
    "        missing_qat.append(tail)\n",
    "    elif \"-PTQ\" in tail:\n",
    "        missing_ptq.append(tail)\n",
    "    else:\n",
    "        missing_baseline.append(tail)\n",
    "        \n",
    "with open(\"missing.txt\", \"w\") as file:\n",
    "    file.write(\"Missing KD:\\n\")\n",
    "    for tail in missing_kd:\n",
    "        file.write(tail + \"\\n\")\n",
    "        \n",
    "    file.write(\"\\nMissing QAT:\\n\")\n",
    "    for tail in missing_qat:\n",
    "        file.write(tail + \"\\n\")\n",
    "        \n",
    "    file.write(\"\\nMissing Baseline:\\n\")\n",
    "    for tail in missing_baseline:\n",
    "        file.write(tail + \"\\n\") \n",
    "        \n",
    "    file.write(\"\\nMissing PTQ:\\n\")\n",
    "    for tail in missing_ptq:\n",
    "        file.write(tail + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l c c c c c c}\n",
      "    \\toprule\n",
      "    & \\multicolumn{3}{c}{KNN-1} & \\multicolumn{3}{c}{KNN-5} \\\\ \n",
      "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
      "    Model  & Accuracy & Precision & F1 Score & Accuracy & Precision & F1 Score \\\\ \n",
      "    \\midrule\n",
      "    EfficientNet Large & 0.7723 & 0.7558 & 0.7516 & 0.6964 & 0.6545 & 0.6585 \\\\\n",
      "    EfficientNet Large PTQ & 0.6429 & 0.5888 & 0.6098 & 0.5759 & 0.5449 & 0.5309 \\\\\n",
      "    EfficientNet Large QAT & 0.4277 & 0.4078 & 0.4153 & 0.4116 & 0.3660 & 0.3822 \\\\\n",
      "    EfficientNet Large QAT\\&KD & 0.7143 & 0.7144 & 0.7136 & 0.2598 & 0.1441 & 0.1663 \\\\\n",
      "    EfficientNet Medium & 0.8404 & 0.8274 & 0.8234 & 0.7589 & 0.7157 & 0.7212 \\\\\n",
      "    EfficientNet Medium PTQ & 0.7946 & 0.7728 & 0.7606 & 0.7232 & 0.6700 & 0.6604 \\\\\n",
      "    EfficientNet Medium QAT & 0.6741 & 0.6624 & 0.6620 & 0.6062 & 0.5795 & 0.5791 \\\\\n",
      "    EfficientNet Medium QAT\\&KD & 0.6232 & 0.6066 & 0.6095 & 0.5652 & 0.5432 & 0.5426 \\\\\n",
      "    EfficientNet Small & 0.8203 & 0.8058 & 0.8034 & 0.7299 & 0.6775 & 0.6888 \\\\\n",
      "    EfficientNet Small PTQ & 0.7813 & 0.7918 & 0.7764 & 0.7143 & 0.6269 & 0.6527 \\\\\n",
      "    EfficientNet Small QAT & 0.8158 & 0.8020 & 0.8013 & 0.7433 & 0.7121 & 0.7145 \\\\\n",
      "    EfficientNet Small QAT\\&KD & 0.7830 & 0.7608 & 0.7652 & 0.7268 & 0.6904 & 0.6942 \\\\\n",
      "    EfficientNetRWM & 0.8742 & 0.8628 & 0.8608 & 0.8096 & 0.7719 & 0.7802 \\\\\n",
      "    EfficientNetRWM PTQ & 0.8750 & 0.8548 & 0.8620 & 0.8170 & 0.7420 & 0.7688 \\\\\n",
      "    EfficientNetRWM QAT & 0.8761 & 0.8642 & 0.8624 & 0.8173 & 0.7718 & 0.7831 \\\\\n",
      "    EfficientNetRWM QAT\\&KD & 0.9109 & 0.9021 & 0.9007 & 0.8547 & 0.8223 & 0.8295 \\\\\n",
      "    ResNet 152 & 0.7656 & 0.7469 & 0.7507 & 0.6931 & 0.6532 & 0.6541 \\\\\n",
      "    ResNet 152 PTQ & 0.6875 & 0.6865 & 0.6766 & 0.6562 & 0.5641 & 0.5921 \\\\\n",
      "    ResNet 152 QAT & 0.7920 & 0.7655 & 0.7703 & 0.7232 & 0.6680 & 0.6825 \\\\\n",
      "    ResNet 152 QAT\\&KD & 0.8650 & 0.8488 & 0.8523 & 0.7902 & 0.7534 & 0.7616 \\\\\n",
      "    ResNet 18 & 0.7812 & 0.7435 & 0.7544 & 0.7121 & 0.6552 & 0.6693 \\\\\n",
      "    ResNet 18 PTQ & 0.7411 & 0.6973 & 0.7153 & 0.6786 & 0.6028 & 0.6254 \\\\\n",
      "    ResNet 18 QAT & 0.7980 & 0.7723 & 0.7777 & 0.7087 & 0.6450 & 0.6625 \\\\\n",
      "    ResNet 18 QAT\\&KD & 0.7375 & 0.7170 & 0.7176 & 0.6679 & 0.6194 & 0.6289 \\\\\n",
      "    ResNet 50 & 0.7321 & 0.7157 & 0.7162 & 0.6775 & 0.6342 & 0.6428 \\\\\n",
      "    ResNet 50 PTQ & 0.6920 & 0.6790 & 0.6757 & 0.6339 & 0.5282 & 0.5612 \\\\\n",
      "    ResNet 50 QAT & 0.7437 & 0.7236 & 0.7270 & 0.6714 & 0.6282 & 0.6382 \\\\\n",
      "    ResNet 50 QAT\\&KD & 0.7946 & 0.7732 & 0.7760 & 0.7304 & 0.6796 & 0.6945 \\\\\n",
      "    SwinV2 Base CXL Open & 0.9408 & 0.9364 & 0.9346 & 0.8828 & 0.8644 & 0.8612 \\\\\n",
      "    SwinV2 Base CXL Open PTQ & 0.9152 & 0.9066 & 0.8987 & 0.8661 & 0.8231 & 0.8269 \\\\\n",
      "    SwinV2 Base CXL Open QAT & 0.9304 & 0.9248 & 0.9211 & 0.8804 & 0.8654 & 0.8616 \\\\\n",
      "    SwinV2 Base CXL Open QAT\\&KD & 0.9268 & 0.9143 & 0.9168 & 0.8527 & 0.8380 & 0.8294 \\\\\n",
      "    SwinV2 Large CXL Open & 0.9319 & 0.9285 & 0.9256 & 0.8661 & 0.8428 & 0.8436 \\\\\n",
      "    SwinV2 Large CXL Open PTQ & 0.8839 & 0.8712 & 0.8590 & 0.8304 & 0.8010 & 0.7842 \\\\\n",
      "    SwinV2 Large CXL Open QAT & 0.9330 & 0.9272 & 0.9232 & 0.8696 & 0.8411 & 0.8435 \\\\\n",
      "    SwinV2 Large CXL Open QAT\\&KD & 0.9286 & 0.9240 & 0.9222 & 0.8580 & 0.8323 & 0.8338 \\\\\n",
      "    SwinV2 Small CXL Open & 0.8962 & 0.8734 & 0.8806 & 0.8371 & 0.7969 & 0.8085 \\\\\n",
      "    SwinV2 Small CXL Open PTQ & 0.9062 & 0.9020 & 0.8921 & 0.8348 & 0.7570 & 0.7836 \\\\\n",
      "    SwinV2 Small CXL Open QAT & 0.9036 & 0.8860 & 0.8890 & 0.8464 & 0.8156 & 0.8176 \\\\\n",
      "    SwinV2 Small CXL Open QAT\\&KD & 0.9286 & 0.9256 & 0.9226 & 0.8634 & 0.8411 & 0.8406 \\\\\n",
      "    ViT Base & 0.8069 & 0.7978 & 0.7952 & 0.7467 & 0.7044 & 0.7113 \\\\\n",
      "    ViT Base PTQ & 0.5956 & 0.5450 & 0.5654 & 0.5733 & 0.5269 & 0.5185 \\\\\n",
      "    ViT Base QAT & 0.8516 & 0.8325 & 0.8355 & 0.7723 & 0.7380 & 0.7424 \\\\\n",
      "    ViT Base QAT\\&KD & 0.9045 & 0.8945 & 0.8925 & 0.8250 & 0.7897 & 0.7977 \\\\\n",
      "    ViT Clip & 0.9163 & 0.9131 & 0.9095 & 0.8415 & 0.8226 & 0.8196 \\\\\n",
      "    ViT Clip PTQ & 0.8259 & 0.8069 & 0.8081 & 0.7679 & 0.7069 & 0.7260 \\\\\n",
      "    ViT Clip QAT & 0.9074 & 0.8995 & 0.8980 & 0.8393 & 0.8183 & 0.8168 \\\\\n",
      "    ViT Clip QAT\\&KD & 0.8984 & 0.8887 & 0.8903 & 0.8382 & 0.8081 & 0.8140 \\\\\n",
      "    ViT DinoV2 & 0.9654 & 0.9591 & 0.9602 & 0.8984 & 0.8768 & 0.8791 \\\\\n",
      "    ViT DinoV2 PTQ & 0.1964 & 0.1989 & 0.1923 & 0.2679 & 0.2165 & 0.2194 \\\\\n",
      "    ViT DinoV2 QAT & 0.9643 & 0.9639 & 0.9619 & 0.9152 & 0.8976 & 0.8997 \\\\\n",
      "    ViT DinoV2 QAT\\&KD & 0.9321 & 0.9290 & 0.9264 & 0.8688 & 0.8504 & 0.8484 \\\\\n",
      "    ViT Large & 0.8161 & 0.7934 & 0.7979 & 0.7429 & 0.6962 & 0.7082 \\\\\n",
      "    ViT Large PTQ & 0.1652 & 0.1631 & 0.1621 & 0.1964 & 0.1122 & 0.1426 \\\\\n",
      "    ViT Large QAT & 0.8071 & 0.7846 & 0.7874 & 0.7223 & 0.6850 & 0.6867 \\\\\n",
      "    ViT Large QAT\\&KD & 0.9196 & 0.9086 & 0.9076 & 0.8545 & 0.8298 & 0.8311 \\\\\n",
      "    \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{Metrics for each architecture.}\n",
      "    \\label{tab:metrics-architecture}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def generate_latex_table(df, metric_names):\n",
    "    # Define the model size order\n",
    "    model_size_order = ['Small', 'Medium', 'Base', 'Large', '18', '50', '152']\n",
    "\n",
    "    # Extract architecture and model size for sorting\n",
    "    def extract_arch_and_size(name):\n",
    "        # Match the last occurrence of the model size (assumed to be at the end)\n",
    "        match = re.search(r'(Small|Medium|Base|Large|18|50|152)$', name)\n",
    "        if match:\n",
    "            size = match.group(0)\n",
    "            arch = name[:match.start()].strip()\n",
    "        else:\n",
    "            size = ''\n",
    "            arch = name.strip()\n",
    "        return arch, size\n",
    "    \n",
    "    # Apply extraction to create separate columns\n",
    "    df[['Arch_Base', 'Model_Size']] = df['name'].apply(lambda x: pd.Series(extract_arch_and_size(x)))\n",
    "\n",
    "    # Sort by architecture and then by the model size order\n",
    "    df['Size_Rank'] = df['Model_Size'].apply(lambda x: model_size_order.index(x) if x in model_size_order else len(model_size_order))\n",
    "    df = df.sort_values(by=['Arch_Base', 'Size_Rank'])\n",
    "    \n",
    "    # If an architecture has the same name but multiple rows choose the row wit the highest knn-1 accuracy\n",
    "    df = df.sort_values(by=['knn-1 accuracy'], ascending=False).drop_duplicates(subset=['Arch_Base'], keep='first')\n",
    "\n",
    "    # Group the data by architecture and calculate metrics\n",
    "    results = []\n",
    "    for arch_base, group in df.groupby('Arch_Base'):\n",
    "        for _, sub_group in group.iterrows():\n",
    "            arch = f\"{sub_group['Arch_Base']} {sub_group['Model_Size']}\".strip()\n",
    "            row = [arch.replace(\"Embedding-\", \"\").replace(\"-CXL-OpenSet\", \"\").replace(\"-\", \" \").replace(\"&\", \"\\&\")]\n",
    "            for metric in metric_names.keys():\n",
    "                value = sub_group[metric]  # Get value for each metric\n",
    "                row.append(f'{value:.4f}')  # Format to four decimal places\n",
    "            results.append(row)\n",
    "\n",
    "    # Build LaTeX table\n",
    "    latex_table = r'''\\begin{table}[H]\n",
    "    \\centering\n",
    "    \\begin{tabular}{l c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{KNN-1} & \\multicolumn{3}{c}{KNN-5} \\\\ \n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "    Model  & ''' + ' & '.join(metric_names.values()) + r''' \\\\ \n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "    for result in results:\n",
    "        latex_table += '    ' + ' & '.join(result) + r' \\\\' + '\\n'\n",
    "\n",
    "    latex_table += r'''    \\bottomrule\n",
    "    \\end{tabular}\n",
    "    \\caption{Metrics for each architecture.}\n",
    "    \\label{tab:metrics-architecture}\n",
    "\\end{table}'''\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "# Example usage\n",
    "# Define the metric names you want to use\n",
    "metric_names = {\n",
    "    'knn-1 accuracy': 'Accuracy',\n",
    "    'knn-1 precision': 'Precision',\n",
    "    'knn-1 f1': 'F1 Score',\n",
    "    'knn-5 accuracy': 'Accuracy',\n",
    "    'knn-5 precision': 'Precision',\n",
    "    'knn-5 f1': 'F1 Score'\n",
    "}\n",
    "\n",
    "# df = your_dataframe_here\n",
    "latex_code = generate_latex_table(dataframe, metric_names)\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l c c c c}\n",
      "    \\toprule\n",
      "    Model & Baseline & PTQ & QAT & QAT\\&KD \\\\\n",
      "    \\midrule\n",
      "    EfficientNet-Small Imagenet 21k & 0.3520 & 0.3226 & 0.2853 & \\textbf{0.4191} \\\\\n",
      "    EfficientNet-Medium Imagenet 21k & \\textbf{0.3752} & 0.3474 & 0.2194 & 0.3096 \\\\\n",
      "    EfficientNet-Large Imagenet 21k & 0.3170 & 0.1158 & 0.1895 & \\textbf{0.6413} \\\\\n",
      "    EfficientNetRWM Imagenet 21k & 0.4434 & 0.4632 & 0.4212 & \\textbf{0.6781} \\\\\n",
      "    ResNet-18 Imagenet 1k & 0.2562 & 0.1789 & 0.2607 & \\textbf{0.3229} \\\\\n",
      "    ResNet-50 Imagenet 1k & 0.2787 & 0.1299 & 0.2673 & \\textbf{0.4151} \\\\\n",
      "    ResNet-152 Imagenet 1k & 0.2302 & 0.1895 & 0.2627 & \\textbf{0.5878} \\\\\n",
      "    SwinV2-Small Imagenet 22k\\&1k & 0.4423 & 0.5053 & 0.4255 & \\textbf{0.7392} \\\\\n",
      "    SwinV2-Base Imagenet 22k\\&1k & 0.5782 & 0.5368 & 0.5275 & \\textbf{0.6854} \\\\\n",
      "    SwinV2-Large Imagenet 22k\\&1k & 0.5549 & 0.4737 & 0.5279 & \\textbf{0.6906} \\\\\n",
      "    ViT-Base Imagenet 21k & 0.3194 & 0.0737 & 0.4016 & \\textbf{0.6347} \\\\\n",
      "    ViT-Large Imagenet 21k & 0.3131 & 0.0215 & 0.3727 & \\textbf{0.7173} \\\\\n",
      "    ViT-Clip CLIP Dataset & 0.5005 & 0.3895 & 0.4629 & \\textbf{0.6528} \\\\\n",
      "    ViT-DinoV2 DINO Dataset & 0.7644 & 0.0430 & \\textbf{0.7669} & 0.7619 \\\\\n",
      "    \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{KNN-1 Accuracy across different configurations.}\n",
      "    \\label{tab:knn1-accuracy-configs}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Mapping of architectures to pretraining datasets\n",
    "architecture_pretrained_mapping = {\n",
    "    \"efficientnet\": \"Imagenet 21k\",\n",
    "    \"resnet\": \"Imagenet 1k\",\n",
    "    \"swin\": \"Imagenet 22k\\&1k\",\n",
    "    \"vit\": \"Imagenet 21k\",\n",
    "    \"dino\": \"DINO Dataset\",\n",
    "    \"clip\": \"CLIP Dataset\",\n",
    "}\n",
    "\n",
    "# Function to extract architecture and variation type, removing \"Embedding-\" prefix\n",
    "def extract_architecture_and_type(name):\n",
    "    base_name = re.sub(r'^Embedding-', '', name)\n",
    "    base_name = re.sub(r'-QAT&KD|-QAT|-PTQ|-CXL-OpenSet|-CXL-Open', '', base_name)\n",
    "    \n",
    "    if 'PTQ' in name:\n",
    "        var_type = 'PTQ'\n",
    "    elif 'QAT&KD' in name:\n",
    "        var_type = 'QAT\\&KD'\n",
    "    elif 'QAT' in name:\n",
    "        var_type = 'QAT'\n",
    "    else:\n",
    "        var_type = 'Baseline'\n",
    "    \n",
    "    base_name_new = \"\"\n",
    "    for architecture, pretrained in architecture_pretrained_mapping.items():\n",
    "        if architecture in base_name.lower():\n",
    "            base_name_new = base_name + \"\\n\" + pretrained\n",
    "            \n",
    "    return base_name_new, var_type\n",
    "\n",
    "# Function to generate LaTeX table with highlighted max values\n",
    "def generate_latex_table_with_configs(df, metric):\n",
    "    # Extract architecture and variation\n",
    "    df['Architecture'], df['Variation'] = zip(*df['name'].apply(extract_architecture_and_type))\n",
    "\n",
    "    # Order by model size\n",
    "    model_size_order = ['Small', 'Medium', 'Base', 'Large', '18', '50', '152']\n",
    "    arch_order = sorted(\n",
    "        df['Architecture'].unique(), \n",
    "        key=lambda x: (\n",
    "            re.sub(r'(Small|Medium|Base|Large|18|50|152)', '', x), \n",
    "            model_size_order.index(re.search(r'(Small|Medium|Base|Large|18|50|152)', x).group(0)) if re.search(r'(Small|Medium|Base|Large|18|50|152)', x) else -1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Group by architecture and variation, taking max accuracy\n",
    "    grouped_df = df.groupby(['Architecture', 'Variation'])[metric].max().unstack()\n",
    "\n",
    "    # Reorder based on architecture order\n",
    "    grouped_df = grouped_df.loc[arch_order]\n",
    "\n",
    "    # Build LaTeX table\n",
    "    latex_table = r'''\\begin{table}[H]\n",
    "    \\centering\n",
    "    \\begin{tabular}{l c c c c}\n",
    "    \\toprule\n",
    "    Model & Baseline & PTQ & QAT & QAT\\&KD \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "    for arch, row in grouped_df.iterrows():\n",
    "        formatted_row = [arch.replace(\"\\n\", \" \")]\n",
    "        for config in ['Baseline', 'PTQ', 'QAT', 'QAT\\&KD']:\n",
    "            value = row.get(config, 'N/A')\n",
    "            if pd.isna(value):\n",
    "                formatted_row.append('N/A')\n",
    "            else:\n",
    "                # Bold the maximum value in the row\n",
    "                if value == row.max():\n",
    "                    formatted_row.append(f'\\\\textbf{{{value:.4f}}}')\n",
    "                else:\n",
    "                    formatted_row.append(f'{value:.4f}')\n",
    "        latex_table += '    ' + ' & '.join(formatted_row) + r' \\\\' + '\\n'\n",
    "\n",
    "    latex_table += r'''    \\bottomrule\n",
    "    \\end{tabular}\n",
    "    \\caption{KNN-1 Accuracy across different configurations.}\n",
    "    \\label{tab:knn1-accuracy-configs}\n",
    "\\end{table}'''\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "# Example usage with the DataFrame `dataframe`\n",
    "latex_code = generate_latex_table_with_configs(dataframe, 'knn-1_crossvideo accuracy')\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from matplotlib.container import ErrorbarContainer\n",
    "\n",
    "architecture_pretrained_mapping = {\n",
    "    \"efficientnet\": \"Imagenet 21k\",\n",
    "    \"resnet\": \"Imagenet 1k\",\n",
    "    \"swin\": \"Imagenet 22k\\&1k\",\n",
    "    \"vit\": \"Imagenet 21k\",\n",
    "    \"dino\": \"DINO Dataset\",\n",
    "    \"clip\": \"CLIP Dataset\",\n",
    "}\n",
    "\n",
    "# Function to extract architecture and variation type, removing \"Embedding-\" prefix\n",
    "def extract_architecture_and_type(name):\n",
    "    base_name = re.sub(r'^Embedding-', '', name)\n",
    "    base_name = re.sub(r'-QAT&KD|-QAT|-PTQ|-CXL-OpenSet|-CXL-Open', '', base_name)\n",
    "    \n",
    "    if 'PTQ' in name:\n",
    "        var_type = 'PTQ'\n",
    "    elif 'QAT&KD' in name:\n",
    "        var_type = 'QAT\\&KD'\n",
    "    elif 'QAT' in name:\n",
    "        var_type = 'QAT'\n",
    "    else:\n",
    "        var_type = 'Baseline'\n",
    "    \n",
    "    base_name_new = \"\"\n",
    "    for architecture, pretrained in architecture_pretrained_mapping.items():\n",
    "        if architecture in base_name.lower():\n",
    "            base_name_new = base_name + \"\\n\" + pretrained\n",
    "            \n",
    "    return base_name_new, var_type\n",
    "\n",
    "# Function to plot bar charts with error bars for a given metric\n",
    "def plot_metric_bars_with_error(df, metric, title):\n",
    "    # Extract architecture and variation\n",
    "    df['Architecture'], df['Variation'] = zip(*df['name'].apply(extract_architecture_and_type))\n",
    "\n",
    "    # Order by model size\n",
    "    model_size_order = ['Small', 'Medium', 'Base', 'Large', '18', '50', '152']\n",
    "    arch_order = sorted(\n",
    "        df['Architecture'].unique(), \n",
    "        key=lambda x: (\n",
    "            re.sub(r'(Small|Medium|Base|Large|18|50|152)', '', x), \n",
    "            model_size_order.index(re.search(r'(Small|Medium|Base|Large|18|50|152)', x).group(0)) if re.search(r'(Small|Medium|Base|Large|18|50|152)', x) else -1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Group by architecture and variation, taking max accuracy and standard deviation\n",
    "    grouped_df = df.groupby(['Architecture', 'Variation'])[metric].max().unstack()\n",
    "    grouped_df_stdev = df.groupby(['Architecture', 'Variation'])[f'{metric} stdev'].max().unstack()\n",
    "\n",
    "    # Reorder based on architecture order\n",
    "    grouped_df = grouped_df.loc[arch_order]\n",
    "    grouped_df_stdev = grouped_df_stdev.loc[arch_order]\n",
    "\n",
    "    # Plot the bar chart with error bars\n",
    "    fig, ax = plt.subplots(figsize=(14, 11))\n",
    "    grouped_df[['Baseline', 'PTQ', 'QAT', 'QAT\\&KD']].plot(kind='bar', ax=ax, yerr=grouped_df_stdev[['Baseline', 'PTQ', 'QAT', 'QAT\\&KD']], capsize=2)\n",
    "\n",
    "    # Set title and labels\n",
    "    plt.title(title.replace(\"&\", \"\\&\"))\n",
    "    plt.ylabel(metric.replace(\"_\", \" \").title())\n",
    "    plt.xlabel('Architecture')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='Variation')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(title + \".pdf\")\n",
    "\n",
    "\n",
    "plot_metric_bars_with_error(dataframe, 'knn-1 accuracy', 'KNN-1 Accuracy for Each Architecture (Baseline, PTQ, QAT, and QAT KD)')\n",
    "plot_metric_bars_with_error(dataframe, 'knn-1_crossvideo accuracy', 'KNN-1 Crossvideo Accuracy for Each Architecture (Baseline, PTQ, QAT, and QAT KD)')\n",
    "plot_metric_bars_with_error(dataframe, 'knn-1_crossvideo precision', 'KNN-1 Crossvideo Precision for Each Architecture (Baseline, PTQ, QAT, and QAT KD)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    \"CNNs\": [\"resnet\", \"efficientnet\"],\n",
    "    \"Transformers\": [\"vit\", \"swin\"],\n",
    "    \"EfficientNet\": [\"efficientnet\"],\n",
    "    \"ResNet\": [\"resnet\"],\n",
    "    \"Swin Transformer\": [\"swin\"],\n",
    "    \"ViT\": [\"vit\"],\n",
    "    \"All\": [\"resnet\", \"efficientnet\", \"vit\", \"swin\"],\n",
    "}\n",
    "\n",
    "df = dataframe\n",
    "\n",
    "for group_name, group in groups.items():\n",
    "    filtered_df = df[df['Architecture'].isin(group)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
